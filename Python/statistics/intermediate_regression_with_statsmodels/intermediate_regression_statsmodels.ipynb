{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d2c1c7",
   "metadata": {},
   "source": [
    "## From Simple to Multiple Regression\n",
    "\n",
    "While simple linear regression models the relationship between a response and a single explanatory variable, **multiple regression** incorporates two or more explanatory variables. This often leads to more insightful and powerful predictive models.\n",
    "\n",
    "A common and useful case of multiple regression involves one numeric and one categorical explanatory variable. This allows us to ask a more nuanced question: \"How does the numeric variable `x` relate to the response `y`, and does this relationship differ between the categories in `c`?\" The parallel slopes model provides a first answer to this by assuming the core relationship (the slope) is the same across all categories, but that each category has a different starting point (the intercept).\n",
    "\n",
    "### The Parallel Slopes Model\n",
    "\n",
    "#### The Core Assumption\n",
    "\n",
    "The fundamental assumption of a parallel slopes model is that the **slope** of the relationship between the numeric explanatory variable and the response variable is **the same for all categories**. The model allows the **intercept** to be different for each category.\n",
    "\n",
    "#### The Model Equations\n",
    "\n",
    "If we have a numeric feature `x` and a categorical feature `c` with three levels (A, B, C), the parallel slopes model is not a single equation, but a set of equations:\n",
    "\n",
    "  * For an observation in category A: $$\\text{response} = \\beta_A + \\beta_{\\text{slope}} \\times x$$\\* For an observation in category B:$$\\text{response} = \\beta_B + \\beta_{\\text{slope}} \\times x$$\\* For an observation in category C:$$\\text{response} = \\beta_C + \\beta_{\\text{slope}} \\times x$$\n",
    "\n",
    "Notice that the slope term, $\\\\beta\\_{\\\\text{slope}}$, is common to all equations, while each category gets its own unique intercept ($\\\\beta\\_A, \\\\beta\\_B, \\\\beta\\_C$).\n",
    "\n",
    "#### The `statsmodels` Formula\n",
    "\n",
    "This model is specified in `statsmodels` with the formula: `response ~ numeric_feature + categorical_feature + 0`.\n",
    "\n",
    "  * `numeric_feature`: This term directs the model to estimate the common slope, $\\\\beta\\_{\\\\text{slope}}$.\n",
    "  * `categorical_feature + 0`: As seen previously, including a categorical variable and explicitly removing the global intercept (`+ 0`) directs the model to estimate a separate intercept for each category.\n",
    "\n",
    "\n",
    "### Implementation and Coefficient Interpretation\n",
    "\n",
    "Let's fit a parallel slopes model and interpret its output.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a generic, reproducible dataset with a parallel slopes structure\n",
    "np.random.seed(42)\n",
    "category = np.random.choice(['Group A', 'Group B', 'Group C'], 150)\n",
    "x_numeric = np.random.uniform(10, 50, 150)\n",
    "# Define different intercepts for each group but a common slope of 3.5\n",
    "intercepts = {'Group A': 50, 'Group B': 80, 'Group C': 20}\n",
    "y_response = np.array([intercepts[cat] for cat in category]) + 3.5 * x_numeric + np.random.normal(0, 15, 150)\n",
    "df = pd.DataFrame({'x_numeric': x_numeric, 'category': category, 'y_response': y_response})\n",
    "\n",
    "# Fit the parallel slopes model \n",
    "mdl_parallel_slopes = smf.ols(\"y_response ~ x_numeric + category + 0\", data=df).fit()\n",
    "\n",
    "# Interpret the coefficients \n",
    "print(mdl_parallel_slopes.params)\n",
    "```\n",
    "\n",
    "The output will look similar to this:\n",
    "\n",
    "```markdown\n",
    "category[Group A]    52.53\n",
    "category[Group B]    81.33\n",
    "category[Group C]    19.71\n",
    "x_numeric             3.47\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "**Interpretation**:\n",
    "\n",
    "  * **`x_numeric` (the slope)**: The coefficient is **3.47**. This means that for *any* category, a one-unit increase in `x_numeric` is associated with an average increase of **3.47** units in `y_response`.\n",
    "  * **`category[Group A]` (intercept)**: The coefficient is **52.53**. This is the predicted `y_response` for an observation in `Group A` when `x_numeric` is zero.\n",
    "  * **`category[Group B]` (intercept)**: The coefficient is **81.33**. This is the predicted `y_response` for an observation in `Group B` when `x_numeric` is zero.\n",
    "  * **`category[Group C]` (intercept)**: The coefficient is **19.71**. This is the predicted `y_response` for an observation in `Group C` when `x_numeric` is zero.\n",
    "\n",
    "\n",
    "### Visualizing the Parallel Slopes Model\n",
    "\n",
    "The best way to understand the model is to visualize its results. We plot the raw data, colored by category, and then overlay the fitted regression line for each category. Because each line shares the same slope, they will be perfectly parallel.\n",
    "\n",
    "```python\n",
    "# 1. Plot the raw data, colored by category\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# 1. Plot the raw data, colored by category\n",
    "sns.scatterplot(x=\"x_numeric\", y=\"y_response\", hue=\"category\", data=df, ax=ax)\n",
    "\n",
    "# 2. Extract the coefficients\n",
    "coeffs = mdl_parallel_slopes.params\n",
    "slope = coeffs['x_numeric']\n",
    "intercept_A = coeffs['category[Group A]']\n",
    "intercept_B = coeffs['category[Group B]']\n",
    "intercept_C = coeffs['category[Group C]']\n",
    "\n",
    "# 3. Add the parallel regression lines for each category\n",
    "ax.axline(xy1=(0, intercept_A), slope=slope, color=sns.color_palette()[0])\n",
    "ax.axline(xy1=(0, intercept_B), slope=slope, color=sns.color_palette()[1])\n",
    "ax.axline(xy1=(0, intercept_C), slope=slope, color=sns.color_palette()[2])\n",
    "\n",
    "ax.set_title(\"Parallel Slopes Regression Model\")\n",
    "ax.set_xlabel(\"Numeric Explanatory Variable\")\n",
    "ax.set_ylabel(\"Response Variable\")\n",
    "ax.grid(True, linestyle='--')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The resulting plot provides a clear and intuitive visualization of the model's structure: three distinct starting points (intercepts) for the three groups, but a single, common trend (slope) that describes the relationship between the numeric feature and the response for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea85e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_points = []\n",
    "exercise_points = []\n",
    "\n",
    "# Input loop\n",
    "while True:\n",
    "    # Get input from user\n",
    "    user_input = input(\"Exam points and exercises completed: \")\n",
    "\n",
    "    # Check if input is empty (just Enter key)\n",
    "    if user_input == \"\":\n",
    "        break  # Exit the loop if empty input\n",
    "\n",
    "    # Split the input into two numbers and convert to integers\n",
    "    # The split() method breaks a string into a list where each word is a list item\n",
    "    points, exercises = map(int, user_input.split())\n",
    "\n",
    "    # Store the data\n",
    "    exam_points.append(points)\n",
    "    exercise_points.append(exercises)\n",
    "\n",
    "\n",
    "def calculate_exercise_points(exercises):\n",
    "    # Convert exercises (0-100) to points (0-10)\n",
    "    return exercises // 10\n",
    "\n",
    "\n",
    "# Calculate statistics\n",
    "total_students = len(exam_points)\n",
    "passing_students = 0\n",
    "grades = [0] * 6  # List to store count of each grade (0-5)\n",
    "\n",
    "total_points = []  # Store total points for average calculation\n",
    "\n",
    "# Process each student's data\n",
    "for i in range(total_students):\n",
    "    # Calculate exercise points\n",
    "    exercise_pts = calculate_exercise_points(exercise_points[i])\n",
    "\n",
    "    # Calculate total points\n",
    "    total = exam_points[i] + exercise_pts\n",
    "    total_points.append(total)\n",
    "\n",
    "    # Determine grade\n",
    "    if exam_points[i] < 10:  # Exam cutoff rule\n",
    "        grade = 0\n",
    "    elif total < 15:\n",
    "        grade = 0\n",
    "    elif total < 18:\n",
    "        grade = 1\n",
    "    elif total < 21:\n",
    "        grade = 2\n",
    "    elif total < 24:\n",
    "        grade = 3\n",
    "    elif total < 28:\n",
    "        grade = 4\n",
    "    else:\n",
    "        grade = 5\n",
    "\n",
    "    grades[grade] += 1\n",
    "\n",
    "    if grade > 0:\n",
    "        passing_students += 1\n",
    "\n",
    "print(\"Statistics:\")\n",
    "points_average = sum(total_points) / total_students\n",
    "pass_percentage = (passing_students / total_students) * 100\n",
    "\n",
    "print(f\"Points average: {points_average:.1f}\")\n",
    "print(f\"Pass percentage: {pass_percentage:.1f}\")\n",
    "\n",
    "# Print grade distribution\n",
    "print(\"Grade distribution:\")\n",
    "for grade in range(5, -1, -1):  # Loop from 5 to 0\n",
    "    stars = \"*\" * grades[grade]  # Create string of stars based on grade count\n",
    "    print(f\"  {grade}: {stars}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
