{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309d10f5",
   "metadata": {},
   "source": [
    "## Data Type Constraints\n",
    "\n",
    "Data type constraints define the permissible formats and values for each variable in a dataset. These constraints are not merely a matter of programming formality; they are essential to ensure data integrity, enable efficient computation, support robust statistical inference, and prevent logical or semantic errors during analysis.\n",
    "\n",
    "Understanding and rigorously applying data type constraints is foundational in data science and engineering, as it directly impacts:\n",
    "\n",
    "- **How data are interpreted and processed**\n",
    "- **What operations are allowed**\n",
    "- **How errors are detected and handled**\n",
    "- **Storage efficiency and computational speed**\n",
    "\n",
    "### Principle Categories of Data Types\n",
    "\n",
    "#### 1. **Text Data (Strings)**\n",
    "- **Python Type:** `str`\n",
    "- **Examples:** Names, addresses, free-text fields\n",
    "- **Constraint:** Arbitrary Unicode/textual data, not inherently orderable or arithmetically manipulable\n",
    "\n",
    "#### 2. **Integers**\n",
    "- **Python Type:** `int`\n",
    "- **Examples:** Counts, IDs, discrete numeric features (number of transactions)\n",
    "- **Constraint:** Must be whole numbers, bounded by implementation\n",
    "\n",
    "#### 3. **Floating Point Numbers (Decimals)**\n",
    "- **Python Type:** `float`\n",
    "- **Examples:** Measurements, continuous variables, financial data\n",
    "- **Constraint:** Support for fractional values, susceptible to floating-point precision issues\n",
    "\n",
    "#### 4. **Booleans**\n",
    "- **Python Type:** `bool`\n",
    "- **Examples:** Binary attributes, flags, logical features\n",
    "- **Constraint:** Only two possible values: `True` or `False`\n",
    "\n",
    "#### 5. **Dates and Times**\n",
    "- **Python Type:** `datetime`\n",
    "- **Examples:** Timestamps, dates of transactions, durations\n",
    "- **Constraint:** Must conform to valid date/time representations, including time zones and formats\n",
    "\n",
    "#### 6. **Categories (Categorical Data)**\n",
    "- **Python Type:** `category`\n",
    "- **Examples:** Gender, marital status, blood type, country codes\n",
    "- **Constraint:** Limited to a finite set of possible values (labels), can be nominal or ordinal, usually improves memory and performance\n",
    "\n",
    "\n",
    "### Why Enforce Data Type Constraints?\n",
    "\n",
    "- **Error Prevention:** Invalid data can be flagged early (e.g., attempting arithmetic on strings, or parsing nonsense dates)\n",
    "- **Logical Clarity:** Clear constraints support unambiguous operations (e.g., cannot average string fields)\n",
    "- **Efficiency:** Memory and CPU are used more effectively (categorical vs. object; integer vs. float)\n",
    "- **Reproducibility:** Ensures consistent processing and interpretation across systems and analysts\n",
    "- **Statistical Correctness:** Summary statistics, regression, and ML models require correct data types for valid results\n",
    "\n",
    "\n",
    "### Setting and Checking Data Types in Python/Pandas\n",
    "\n",
    "Pandas, as a Python data analysis library, is strongly type-aware and provides flexible tools for setting, checking, and converting data types.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV while enforcing data types\n",
    "dtypes = {\n",
    "    'age': 'int',\n",
    "    'name': 'str',\n",
    "    'is_member': 'bool',\n",
    "    'signup_date': 'datetime64[ns]',\n",
    "    'membership_type': 'category'\n",
    "}\n",
    "df = pd.read_csv('data.csv', dtype=dtypes, parse_dates=['signup_date'])\n",
    "\n",
    "# Checking data types\n",
    "print(df.dtypes)\n",
    "```\n",
    "\n",
    "* **Changing data types after reading:**\n",
    "  Use `.astype()` for type conversion, `.to_datetime()` for dates, and `.astype('category')` for categorical data.\n",
    "\n",
    "### Data Type Inference and Automatic Conversion\n",
    "\n",
    "* **Pandas' automatic type inference:**\n",
    "  On reading, pandas tries to infer column types, but this can be error-prone with mixed or ambiguous data (e.g., '001' vs 1, dates in odd formats, etc).\n",
    "* **Explicit type setting is always preferable for reliability.**\n",
    "\n",
    "\n",
    "### Numeric vs. Categorical â€” A Crucial Distinction\n",
    "\n",
    "Some columns may contain numbers but should be treated as categories (e.g., codes, labels, ordinal groups). Conversely, a categorical-looking field may be encoded as integers and require conversion for correct analysis.\n",
    "\n",
    "* **Numeric coded categorical:** Should use `category` not `int`, as statistical summaries (mean, std) are not meaningful.\n",
    "* **Categorical to numeric:** Sometimes category labels need to be mapped to numbers (label encoding, one-hot encoding).\n",
    "\n",
    "### Enforcing Data Type Constraints \n",
    "\n",
    "* **Validate data types upon data import** (e.g., `df.dtypes`, `df.info()`)\n",
    "* **Convert and coerce data as required** (`.astype()`, `.to_datetime()`)\n",
    "* **Assert data type expectations** using Python's `assert` statement for robust code:\n",
    "\n",
    "  ```python\n",
    "  assert df['age'].dtype == 'int'\n",
    "  ```\n",
    "* **Handle non-conforming values** (e.g., parse errors, missing values) through coercion or pre-cleaning.\n",
    "\n",
    "\n",
    "### Data Type Constraints in Python\n",
    "\n",
    "| Datatype   | Example                       | Python Data Type |\n",
    "| ---------- | ----------------------------- | ---------------- |\n",
    "| Text       | First name, address           | `str`            |\n",
    "| Integer    | Customer count, quantity sold | `int`            |\n",
    "| Decimal    | Temperature, exchange rate    | `float`          |\n",
    "| Binary     | Yes/No, is\\_active            | `bool`           |\n",
    "| Dates      | Ship date, signup date        | `datetime`       |\n",
    "| Categories | Gender, marital status        | `category`       |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5760c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e5acfb",
   "metadata": {},
   "source": [
    "### Numeric data or ... ?\n",
    "This dataset is from bicycle ride sharing data in San Francisco called ride_sharing. It contains information on the start and end stations, the trip duration, and some user information for a bike sharing service.\n",
    "\n",
    "The user_type column contains information on whether a user is taking a free ride and takes on the following values:\n",
    "\n",
    "1) for free riders.\n",
    "2) for pay per ride.\n",
    "3) for monthly subscribers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa372a6",
   "metadata": {},
   "source": [
    "```python\n",
    "# Generate random dates between 2017-01-25 and 2020-01-17\n",
    "start_date = pd.to_datetime('2017-01-25')\n",
    "end_date = pd.to_datetime('2020-01-17')\n",
    "\n",
    "# Calculate the number of days between start and end dates\n",
    "date_range = (end_date - start_date).days\n",
    "\n",
    "# Generate random dates for each row\n",
    "random_days = np.random.randint(0, date_range + 1, size=len(ride_sharing))\n",
    "ride_sharing[\"ride_date\"] = start_date + pd.to_timedelta(random_days, unit='D')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f5b9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "duration",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_A_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_B_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_B_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bike_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tire_sizes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ride_date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "7363e833-5744-4171-b53a-a1d393b8321a",
       "rows": [
        [
         "0",
         "12 minutes",
         "81",
         "Berry St at 4th St",
         "323",
         "Broadway at Kearny",
         "5480",
         "Subscriber",
         "1959",
         "Male",
         "27.0",
         "2018-09-22"
        ],
        [
         "1",
         "24 minutes",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "118",
         "Eureka Valley Recreation Center",
         "5193",
         "Subscriber",
         "1965",
         "Male",
         "26.0",
         "2019-06-15"
        ],
        [
         "2",
         "8 minutes",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "23",
         "The Embarcadero at Steuart St",
         "3652",
         "Subscriber",
         "1993",
         "Male",
         "26.0",
         "2019-01-01"
        ],
        [
         "3",
         "4 minutes",
         "16",
         "Steuart St at Market St",
         "28",
         "The Embarcadero at Bryant St",
         "1883",
         "Subscriber",
         "1979",
         "Male",
         "29.0",
         "2018-10-17"
        ],
        [
         "4",
         "11 minutes",
         "22",
         "Howard St at Beale St",
         "350",
         "8th St at Brannan St",
         "4626",
         "Subscriber",
         "1994",
         "Male",
         "27.0",
         "2017-02-03"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>tire_sizes</th>\n",
       "      <th>ride_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 minutes</td>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>323</td>\n",
       "      <td>Broadway at Kearny</td>\n",
       "      <td>5480</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1959</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2018-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24 minutes</td>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>5193</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1965</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8 minutes</td>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>23</td>\n",
       "      <td>The Embarcadero at Steuart St</td>\n",
       "      <td>3652</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1993</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 minutes</td>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>28</td>\n",
       "      <td>The Embarcadero at Bryant St</td>\n",
       "      <td>1883</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1979</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2018-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 minutes</td>\n",
       "      <td>22</td>\n",
       "      <td>Howard St at Beale St</td>\n",
       "      <td>350</td>\n",
       "      <td>8th St at Brannan St</td>\n",
       "      <td>4626</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1994</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2017-02-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration  station_A_id  \\\n",
       "0  12 minutes            81   \n",
       "1  24 minutes             3   \n",
       "2   8 minutes            67   \n",
       "3   4 minutes            16   \n",
       "4  11 minutes            22   \n",
       "\n",
       "                                      station_A_name  station_B_id  \\\n",
       "0                                 Berry St at 4th St           323   \n",
       "1       Powell St BART Station (Market St at 4th St)           118   \n",
       "2  San Francisco Caltrain Station 2  (Townsend St...            23   \n",
       "3                            Steuart St at Market St            28   \n",
       "4                              Howard St at Beale St           350   \n",
       "\n",
       "                    station_B_name  bike_id   user_type  user_birth_year  \\\n",
       "0               Broadway at Kearny     5480  Subscriber             1959   \n",
       "1  Eureka Valley Recreation Center     5193  Subscriber             1965   \n",
       "2    The Embarcadero at Steuart St     3652  Subscriber             1993   \n",
       "3     The Embarcadero at Bryant St     1883  Subscriber             1979   \n",
       "4             8th St at Brannan St     4626  Subscriber             1994   \n",
       "\n",
       "  user_gender  tire_sizes   ride_date  \n",
       "0        Male        27.0  2018-09-22  \n",
       "1        Male        26.0  2019-06-15  \n",
       "2        Male        26.0  2019-01-01  \n",
       "3        Male        29.0  2018-10-17  \n",
       "4        Male        27.0  2017-02-03  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jhlopesalves/data-science-practice-notebook/refs/heads/main/Python/data_manipulation/pandas/cleaning_data/data/ride_sharing_new.csv\"\n",
    "\n",
    "ride_sharing = pd.read_csv(url, usecols=lambda col: not col.startswith(\"Unnamed\"))\n",
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2524fa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25760 entries, 0 to 25759\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   duration         25760 non-null  object \n",
      " 1   station_A_id     25760 non-null  int64  \n",
      " 2   station_A_name   25760 non-null  object \n",
      " 3   station_B_id     25760 non-null  int64  \n",
      " 4   station_B_name   25760 non-null  object \n",
      " 5   bike_id          25760 non-null  int64  \n",
      " 6   user_type        25760 non-null  object \n",
      " 7   user_birth_year  25760 non-null  int64  \n",
      " 8   user_gender      25760 non-null  object \n",
      " 9   tire_sizes       25760 non-null  float64\n",
      " 10  ride_date        25760 non-null  object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ride_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669348cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_type",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "b2fa4460-6db5-4cfd-a202-d68f24fb415f",
       "rows": [
        [
         "count",
         "25760"
        ],
        [
         "unique",
         "2"
        ],
        [
         "top",
         "Subscriber"
        ],
        [
         "freq",
         "23209"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "count          25760\n",
       "unique             2\n",
       "top       Subscriber\n",
       "freq           23209\n",
       "Name: user_type, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print summary statistics of user_type column\n",
    "ride_sharing[\"user_type\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f305d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user_type into categorical by assigning it the 'category' data type and store it in the user_type_cat column.\n",
    "ride_sharing[\"user_type_cat\"] = ride_sharing[\"user_type\"].astype(\"category\")\n",
    "\n",
    "# Write an assert statement confirming the change\n",
    "assert ride_sharing[\"user_type_cat\"].dtype == \"category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318de41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_type_cat",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "7de29a56-127d-41e9-9a53-005a774c43c7",
       "rows": [
        [
         "count",
         "25760"
        ],
        [
         "unique",
         "2"
        ],
        [
         "top",
         "Subscriber"
        ],
        [
         "freq",
         "23209"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "count          25760\n",
       "unique             2\n",
       "top       Subscriber\n",
       "freq           23209\n",
       "Name: user_type_cat, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print new summary statistics\n",
    "ride_sharing[\"user_type_cat\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d52e20",
   "metadata": {},
   "source": [
    "Another common data type problem is importing what should be numerical values as strings, as mathematical operations such as summing and multiplication lead to string concatenation, not numerical outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b471bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .strip() method to strip duration of \"minutes\" and store it in the duration_trim column.\n",
    "ride_sharing[\"duration_trim\"] = ride_sharing[\"duration\"].str.strip(\"minutes\")\n",
    "\n",
    "ride_sharing[\"duration_time\"] = ride_sharing[\"duration_trim\"].astype(\"int\")\n",
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing[\"duration_time\"].dtype == \"int\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212ce3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.389052795031056\n"
     ]
    }
   ],
   "source": [
    "# Print formed columns and calculate average ride duration\n",
    "print(np.mean(ride_sharing[\"duration_time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd39c687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_B_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_B_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bike_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tire_sizes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ride_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_type_cat",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "duration_time",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7aa8de96-a4e1-4212-8511-e5a40dc069f7",
       "rows": [
        [
         "0",
         "81",
         "Berry St at 4th St",
         "323",
         "Broadway at Kearny",
         "5480",
         "Subscriber",
         "1959",
         "Male",
         "27.0",
         "2018-09-22",
         "Subscriber",
         "12"
        ],
        [
         "1",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "118",
         "Eureka Valley Recreation Center",
         "5193",
         "Subscriber",
         "1965",
         "Male",
         "26.0",
         "2019-06-15",
         "Subscriber",
         "24"
        ],
        [
         "2",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "23",
         "The Embarcadero at Steuart St",
         "3652",
         "Subscriber",
         "1993",
         "Male",
         "26.0",
         "2019-01-01",
         "Subscriber",
         "8"
        ],
        [
         "3",
         "16",
         "Steuart St at Market St",
         "28",
         "The Embarcadero at Bryant St",
         "1883",
         "Subscriber",
         "1979",
         "Male",
         "29.0",
         "2018-10-17",
         "Subscriber",
         "4"
        ],
        [
         "4",
         "22",
         "Howard St at Beale St",
         "350",
         "8th St at Brannan St",
         "4626",
         "Subscriber",
         "1994",
         "Male",
         "27.0",
         "2017-02-03",
         "Subscriber",
         "11"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>tire_sizes</th>\n",
       "      <th>ride_date</th>\n",
       "      <th>user_type_cat</th>\n",
       "      <th>duration_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>323</td>\n",
       "      <td>Broadway at Kearny</td>\n",
       "      <td>5480</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1959</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>5193</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1965</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>23</td>\n",
       "      <td>The Embarcadero at Steuart St</td>\n",
       "      <td>3652</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1993</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>28</td>\n",
       "      <td>The Embarcadero at Bryant St</td>\n",
       "      <td>1883</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1979</td>\n",
       "      <td>Male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Howard St at Beale St</td>\n",
       "      <td>350</td>\n",
       "      <td>8th St at Brannan St</td>\n",
       "      <td>4626</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1994</td>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_A_id                                     station_A_name  \\\n",
       "0            81                                 Berry St at 4th St   \n",
       "1             3       Powell St BART Station (Market St at 4th St)   \n",
       "2            67  San Francisco Caltrain Station 2  (Townsend St...   \n",
       "3            16                            Steuart St at Market St   \n",
       "4            22                              Howard St at Beale St   \n",
       "\n",
       "   station_B_id                   station_B_name  bike_id   user_type  \\\n",
       "0           323               Broadway at Kearny     5480  Subscriber   \n",
       "1           118  Eureka Valley Recreation Center     5193  Subscriber   \n",
       "2            23    The Embarcadero at Steuart St     3652  Subscriber   \n",
       "3            28     The Embarcadero at Bryant St     1883  Subscriber   \n",
       "4           350             8th St at Brannan St     4626  Subscriber   \n",
       "\n",
       "   user_birth_year user_gender  tire_sizes   ride_date user_type_cat  \\\n",
       "0             1959        Male        27.0  2018-09-22    Subscriber   \n",
       "1             1965        Male        26.0  2019-06-15    Subscriber   \n",
       "2             1993        Male        26.0  2019-01-01    Subscriber   \n",
       "3             1979        Male        29.0  2018-10-17    Subscriber   \n",
       "4             1994        Male        27.0  2017-02-03    Subscriber   \n",
       "\n",
       "   duration_time  \n",
       "0             12  \n",
       "1             24  \n",
       "2              8  \n",
       "3              4  \n",
       "4             11  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing = ride_sharing.drop([\"duration\", \"duration_trim\"], axis=1)\n",
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d2de1",
   "metadata": {},
   "source": [
    "Bicycle tire sizes could be either 26â€³, 27â€³ or 29â€³ and are here correctly stored as a categorical value. In an effort to cut maintenance costs, the ride sharing provider decided to set the maximum tire size to be 27â€³."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48dc37bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     25760\n",
      "unique        2\n",
      "top          27\n",
      "freq      13274\n",
      "Name: tire_sizes, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the tire_sizes column from category to 'int'.\n",
    "ride_sharing[\"tire_sizes\"] = ride_sharing[\"tire_sizes\"].astype(\"int\")\n",
    "\n",
    "# Use .loc[] to set all values of tire_sizes above 27 to 27.\n",
    "ride_sharing.loc[ride_sharing[\"tire_sizes\"] > 27, \"tire_sizes\"] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing[\"tire_sizes\"] = ride_sharing[\"tire_sizes\"].astype(\"category\")\n",
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing[\"tire_sizes\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f43649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-17\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Convert ride_date to date\n",
    "ride_sharing[\"ride_dt\"] = pd.to_datetime(ride_sharing[\"ride_date\"]).dt.date\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "ride_sharing.loc[ride_sharing[\"ride_dt\"] > today, \"ride_dt\"] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(ride_sharing[\"ride_dt\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a55c80aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_B_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_B_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bike_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tire_sizes",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "ride_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_type_cat",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "duration_time",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ride_dt",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "7a737731-21fc-4944-9c1f-5863535d3534",
       "rows": [
        [
         "0",
         "81",
         "Berry St at 4th St",
         "323",
         "Broadway at Kearny",
         "5480",
         "Subscriber",
         "1959",
         "Male",
         "27",
         "2018-09-22",
         "Subscriber",
         "12",
         "2018-09-22"
        ],
        [
         "1",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "118",
         "Eureka Valley Recreation Center",
         "5193",
         "Subscriber",
         "1965",
         "Male",
         "26",
         "2019-06-15",
         "Subscriber",
         "24",
         "2019-06-15"
        ],
        [
         "2",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "23",
         "The Embarcadero at Steuart St",
         "3652",
         "Subscriber",
         "1993",
         "Male",
         "26",
         "2019-01-01",
         "Subscriber",
         "8",
         "2019-01-01"
        ],
        [
         "3",
         "16",
         "Steuart St at Market St",
         "28",
         "The Embarcadero at Bryant St",
         "1883",
         "Subscriber",
         "1979",
         "Male",
         "27",
         "2018-10-17",
         "Subscriber",
         "4",
         "2018-10-17"
        ],
        [
         "4",
         "22",
         "Howard St at Beale St",
         "350",
         "8th St at Brannan St",
         "4626",
         "Subscriber",
         "1994",
         "Male",
         "27",
         "2017-02-03",
         "Subscriber",
         "11",
         "2017-02-03"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>tire_sizes</th>\n",
       "      <th>ride_date</th>\n",
       "      <th>user_type_cat</th>\n",
       "      <th>duration_time</th>\n",
       "      <th>ride_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>323</td>\n",
       "      <td>Broadway at Kearny</td>\n",
       "      <td>5480</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1959</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-09-22</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>118</td>\n",
       "      <td>Eureka Valley Recreation Center</td>\n",
       "      <td>5193</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1965</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>24</td>\n",
       "      <td>2019-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>23</td>\n",
       "      <td>The Embarcadero at Steuart St</td>\n",
       "      <td>3652</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1993</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>28</td>\n",
       "      <td>The Embarcadero at Bryant St</td>\n",
       "      <td>1883</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1979</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-10-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>Howard St at Beale St</td>\n",
       "      <td>350</td>\n",
       "      <td>8th St at Brannan St</td>\n",
       "      <td>4626</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1994</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-02-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_A_id                                     station_A_name  \\\n",
       "0            81                                 Berry St at 4th St   \n",
       "1             3       Powell St BART Station (Market St at 4th St)   \n",
       "2            67  San Francisco Caltrain Station 2  (Townsend St...   \n",
       "3            16                            Steuart St at Market St   \n",
       "4            22                              Howard St at Beale St   \n",
       "\n",
       "   station_B_id                   station_B_name  bike_id   user_type  \\\n",
       "0           323               Broadway at Kearny     5480  Subscriber   \n",
       "1           118  Eureka Valley Recreation Center     5193  Subscriber   \n",
       "2            23    The Embarcadero at Steuart St     3652  Subscriber   \n",
       "3            28     The Embarcadero at Bryant St     1883  Subscriber   \n",
       "4           350             8th St at Brannan St     4626  Subscriber   \n",
       "\n",
       "   user_birth_year user_gender tire_sizes   ride_date user_type_cat  \\\n",
       "0             1959        Male         27  2018-09-22    Subscriber   \n",
       "1             1965        Male         26  2019-06-15    Subscriber   \n",
       "2             1993        Male         26  2019-01-01    Subscriber   \n",
       "3             1979        Male         27  2018-10-17    Subscriber   \n",
       "4             1994        Male         27  2017-02-03    Subscriber   \n",
       "\n",
       "   duration_time     ride_dt  \n",
       "0             12  2018-09-22  \n",
       "1             24  2019-06-15  \n",
       "2              8  2019-01-01  \n",
       "3              4  2018-10-17  \n",
       "4             11  2017-02-03  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97339b",
   "metadata": {},
   "source": [
    "## Uniqueness Constraints\n",
    "\n",
    "Uniqueness constraints in data refer to the expectation or requirement that specific records within a dataset are distinct, without duplication. Violating uniqueness constraints can lead to misrepresentations, distorted analytics, and compromised database integrity.\n",
    "\n",
    "### Understanding Duplicate Values\n",
    "\n",
    "A **duplicate** occurs when two or more records contain identical or near-identical information across certain or all columns. Duplicates may be:\n",
    "\n",
    "- **Complete duplicates**: All column values match exactly.\n",
    "- **Partial duplicates**: Only some subset of columns match exactly.\n",
    "\n",
    "Identifying and addressing duplicates is fundamental in data cleaning, ensuring reliable analysis and reporting.\n",
    "\n",
    "### Identifying Duplicate Records\n",
    "\n",
    "#### 1. Using `.duplicated()` in pandas\n",
    "\n",
    "The `.duplicated()` method returns a boolean Series indicating duplicate rows:\n",
    "\n",
    "```python\n",
    "# Check duplicates across all columns\n",
    "duplicates = df.duplicated()\n",
    "\n",
    "# Display duplicate records\n",
    "df[duplicates]\n",
    "````\n",
    "\n",
    "#### 2. Identifying Duplicates Across Specific Columns\n",
    "\n",
    "You can specify subsets of columns to focus the search for duplicates:\n",
    "\n",
    "```python\n",
    "# Specify columns to identify duplicates\n",
    "subset_cols = ['first_name', 'last_name', 'address']\n",
    "\n",
    "duplicates = df.duplicated(subset=subset_cols, keep=False)\n",
    "\n",
    "# Display sorted duplicates clearly\n",
    "df[duplicates].sort_values(by=subset_cols)\n",
    "```\n",
    "\n",
    "#### Important parameters in `.duplicated()`:\n",
    "\n",
    "* `subset`: List of column names to consider when checking for duplicates.\n",
    "* `keep`: Determines which duplicates to mark:\n",
    "\n",
    "  * `'first'`: Mark duplicates except the first occurrence.\n",
    "  * `'last'`: Mark duplicates except the last occurrence.\n",
    "  * `False`: Mark all duplicates.\n",
    "\n",
    "```python\n",
    "# Example marking all duplicates\n",
    "duplicates_all = df.duplicated(subset=subset_cols, keep=False)\n",
    "```\n",
    "### Treating and Handling Duplicate Values\n",
    "\n",
    "#### Method 1: Removing Duplicates using `.drop_duplicates()`\n",
    "\n",
    "`.drop_duplicates()` removes duplicate rows directly:\n",
    "\n",
    "```python\n",
    "# Drop duplicate rows across entire DataFrame\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop duplicates based on subset of columns\n",
    "df.drop_duplicates(subset=subset_cols, keep='first', inplace=True)\n",
    "```\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "* `subset`: Columns to consider for identifying duplicates.\n",
    "* `keep`: Controls which duplicates to retain (`'first'`, `'last'`, or `False`).\n",
    "* `inplace`: Updates the DataFrame directly if set to `True`.\n",
    "\n",
    "#### Method 2: Aggregating duplicates using `.groupby()` and `.agg()`\n",
    "\n",
    "This approach allows you to summarize data across duplicates rather than just removing them:\n",
    "\n",
    "```python\n",
    "# Define columns for duplicate identification\n",
    "subset_cols = ['first_name', 'last_name', 'address']\n",
    "\n",
    "# Define aggregation rules\n",
    "agg_rules = {\n",
    "    'height': 'mean',  # average height\n",
    "    'weight': 'max'    # maximum weight\n",
    "}\n",
    "\n",
    "# Aggregate duplicates based on rules\n",
    "df_clean = df.groupby(subset_cols).agg(agg_rules).reset_index()\n",
    "```\n",
    "\n",
    "### Verifying the Treatment of Duplicates\n",
    "\n",
    "Always verify the effectiveness of your cleaning methods using `.duplicated()` again:\n",
    "\n",
    "```python\n",
    "# Confirm no duplicates remain\n",
    "duplicates_remaining = df_clean.duplicated(subset=subset_cols, keep=False)\n",
    "assert not duplicates_remaining.any(), \"Duplicates still remain!\"\n",
    "```\n",
    "\n",
    "### Pythonic Best Practices for Handling Duplicates\n",
    "\n",
    "* **Explicit is Better than Implicit:** Clearly state the columns you're checking for duplication. Do not rely solely on defaults.\n",
    "* **Assertions for Validation:** After treatment, ensure that duplicates no longer exist.\n",
    "* **Use `groupby()` and `agg()` for Complex Scenarios:** When dropping duplicates outright is undesirable (due to loss of data richness), aggregations provide more nuanced approaches.\n",
    "\n",
    "```python\n",
    "# Pythonic verification of duplicate removal\n",
    "assert df.duplicated(subset=subset_cols).sum() == 0, \"Duplicates found after cleaning!\"\n",
    "```\n",
    "\n",
    "### Theoretical and Practical Considerations\n",
    "\n",
    "* **Business Context:** Always handle duplicates based on domain-specific rules. For example, duplicates might represent genuine repeated transactions.\n",
    "* **Impact on Analytics:** Duplicates can skew averages, sums, and frequency counts, leading to misleading analytics.\n",
    "* **Database Constraints:** Database systems use unique constraints and keys to enforce data integrity, which mirrors the concept of duplicates in data science.\n",
    "* **Data Provenance and Traceability:** Carefully document decisions around duplicates, including the reasoning for either removal or aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80d40114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ride_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "duration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_B_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_B_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bike_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tire_sizes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ride_date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "08f614cf-473f-41ce-88e4-9c1b83a3cd9a",
       "rows": [
        [
         "0",
         "0",
         "11",
         "16",
         "Steuart St at Market St",
         "93",
         "4th St at Mission Bay Blvd S",
         "5504",
         "Subscriber",
         "1988",
         "Male",
         "27",
         "2018-03-04"
        ],
        [
         "1",
         "1",
         "8",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "93",
         "4th St at Mission Bay Blvd S",
         "2915",
         "Subscriber",
         "1988",
         "Male",
         "27",
         "2017-03-27"
        ],
        [
         "2",
         "2",
         "11",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "5340",
         "Customer",
         "1988",
         "Male",
         "26",
         "2019-06-30"
        ],
        [
         "3",
         "3",
         "7",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "50",
         "2nd St at Townsend St",
         "746",
         "Subscriber",
         "1969",
         "Male",
         "27",
         "2018-11-16"
        ],
        [
         "4",
         "4",
         "11",
         "81",
         "Berry St at 4th St",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "5477",
         "Subscriber",
         "1986",
         "Male",
         "26",
         "2017-11-01"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>tire_sizes</th>\n",
       "      <th>ride_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>93</td>\n",
       "      <td>4th St at Mission Bay Blvd S</td>\n",
       "      <td>5504</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>93</td>\n",
       "      <td>4th St at Mission Bay Blvd S</td>\n",
       "      <td>2915</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1988</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>San Francisco Ferry Building (Harry Bridges Pl...</td>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>5340</td>\n",
       "      <td>Customer</td>\n",
       "      <td>1988</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>2019-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>Montgomery St BART Station (Market St at 2nd St)</td>\n",
       "      <td>50</td>\n",
       "      <td>2nd St at Townsend St</td>\n",
       "      <td>746</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>21</td>\n",
       "      <td>Montgomery St BART Station (Market St at 2nd St)</td>\n",
       "      <td>5477</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1986</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ride_id  duration  station_A_id  \\\n",
       "0        0        11            16   \n",
       "1        1         8             3   \n",
       "2        2        11            15   \n",
       "3        3         7            21   \n",
       "4        4        11            81   \n",
       "\n",
       "                                      station_A_name  station_B_id  \\\n",
       "0                            Steuart St at Market St            93   \n",
       "1       Powell St BART Station (Market St at 4th St)            93   \n",
       "2  San Francisco Ferry Building (Harry Bridges Pl...            67   \n",
       "3   Montgomery St BART Station (Market St at 2nd St)            50   \n",
       "4                                 Berry St at 4th St            21   \n",
       "\n",
       "                                      station_B_name  bike_id   user_type  \\\n",
       "0                       4th St at Mission Bay Blvd S     5504  Subscriber   \n",
       "1                       4th St at Mission Bay Blvd S     2915  Subscriber   \n",
       "2  San Francisco Caltrain Station 2  (Townsend St...     5340    Customer   \n",
       "3                              2nd St at Townsend St      746  Subscriber   \n",
       "4   Montgomery St BART Station (Market St at 2nd St)     5477  Subscriber   \n",
       "\n",
       "   user_birth_year user_gender  tire_sizes   ride_date  \n",
       "0             1988        Male          27  2018-03-04  \n",
       "1             1988        Male          27  2017-03-27  \n",
       "2             1988        Male          26  2019-06-30  \n",
       "3             1969        Male          27  2018-11-16  \n",
       "4             1986        Male          26  2017-11-01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jhlopesalves/data-science-practice-notebook/refs/heads/main/Python/data_manipulation/pandas/cleaning_data/data/ride_sharing_id.csv\"\n",
    "ride_sharing_id = pd.read_csv(url, usecols=lambda col: not col.startswith(\"Unnamed\"))\n",
    "ride_sharing_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d119c703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ride_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "duration",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_birth_year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "51fdc999-3372-4cc6-a672-e27ba8a6c7e0",
       "rows": [
        [
         "22",
         "33",
         "10",
         "1979"
        ],
        [
         "39",
         "33",
         "2",
         "1979"
        ],
        [
         "53",
         "55",
         "9",
         "1985"
        ],
        [
         "65",
         "55",
         "9",
         "1985"
        ],
        [
         "74",
         "71",
         "11",
         "1997"
        ],
        [
         "75",
         "71",
         "11",
         "1997"
        ],
        [
         "76",
         "89",
         "9",
         "1986"
        ],
        [
         "77",
         "89",
         "9",
         "2060"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>user_birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>55</td>\n",
       "      <td>9</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>89</td>\n",
       "      <td>9</td>\n",
       "      <td>2060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ride_id  duration  user_birth_year\n",
       "22       33        10             1979\n",
       "39       33         2             1979\n",
       "53       55         9             1985\n",
       "65       55         9             1985\n",
       "74       71        11             1997\n",
       "75       71        11             1997\n",
       "76       89         9             1986\n",
       "77       89         9             2060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find duplicated rows of ride_id in the ride_sharing DataFrame while setting keep to False.\n",
    "duplicates = ride_sharing_id[\"ride_id\"].duplicated(keep=False)\n",
    "\n",
    "# Subset ride_sharing on duplicates and sort by ride_id and assign the results to duplicated_rides.\n",
    "duplicated_rides = ride_sharing_id[duplicates].sort_values(by=\"ride_id\")\n",
    "\n",
    "# Print the ride_id, duration and user_birth_year columns of duplicated_rides in that order.\n",
    "display(duplicated_rides[[\"ride_id\", \"duration\", \"user_birth_year\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42f30312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop complete duplicates in ride_sharing and store the results in ride_dup.\n",
    "ride_dup = ride_sharing_id.drop_duplicates()\n",
    "\n",
    "# Create the statistics dictionary which holds minimum aggregation for user_birth_year and mean aggregation for duration.\n",
    "statistics = {\"user_birth_year\": \"min\", \"duration\": \"mean\"}\n",
    "\n",
    "# Drop incomplete duplicates by grouping by ride_id and applying the aggregation in statistics.\n",
    "ride_unique = ride_dup.groupby(\"ride_id\").agg(statistics).reset_index()\n",
    "\n",
    "# Apply the same duplicate removal process directly to ride_sharing_id\n",
    "# First drop complete duplicates from the original dataset\n",
    "ride_sharing_id = ride_sharing_id.drop_duplicates()\n",
    "\n",
    "# Then handle incomplete duplicates by grouping by ride_id and applying aggregation rules\n",
    "# For user_birth_year: use 'min' to get the earliest/lowest birth year (most conservative age estimate)\n",
    "# For duration: use 'mean' to average the trip duration across duplicate rides\n",
    "# For all other columns: use 'first' to keep the first occurrence's value since they should be identical for the same ride_id\n",
    "ride_sharing_id = (\n",
    "    ride_sharing_id.groupby(\"ride_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"user_birth_year\": \"min\",\n",
    "            \"duration\": \"mean\",\n",
    "            \"station_A_id\": \"first\",\n",
    "            \"station_A_name\": \"first\",\n",
    "            \"station_B_id\": \"first\",\n",
    "            \"station_B_name\": \"first\",\n",
    "            \"bike_id\": \"first\",\n",
    "            \"user_type\": \"first\",\n",
    "            \"user_gender\": \"first\",\n",
    "            \"tire_sizes\": \"first\",\n",
    "            \"ride_date\": \"first\",\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5ba3567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ride_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_birth_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "station_A_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_A_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "station_B_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "station_B_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bike_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "user_gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tire_sizes",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ride_date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "fa9b92de-dfa0-46eb-bfd1-1cf15236a9cc",
       "rows": [
        [
         "0",
         "0",
         "1988",
         "11.0",
         "16",
         "Steuart St at Market St",
         "93",
         "4th St at Mission Bay Blvd S",
         "5504",
         "Subscriber",
         "Male",
         "27",
         "2018-03-04"
        ],
        [
         "1",
         "1",
         "1988",
         "8.0",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "93",
         "4th St at Mission Bay Blvd S",
         "2915",
         "Subscriber",
         "Male",
         "27",
         "2017-03-27"
        ],
        [
         "2",
         "2",
         "1988",
         "11.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "5340",
         "Customer",
         "Male",
         "26",
         "2019-06-30"
        ],
        [
         "3",
         "3",
         "1969",
         "7.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "50",
         "2nd St at Townsend St",
         "746",
         "Subscriber",
         "Male",
         "27",
         "2018-11-16"
        ],
        [
         "4",
         "4",
         "1986",
         "11.0",
         "81",
         "Berry St at 4th St",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "5477",
         "Subscriber",
         "Male",
         "26",
         "2017-11-01"
        ],
        [
         "5",
         "5",
         "1963",
         "5.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "37",
         "2nd St at Folsom St",
         "223",
         "Subscriber",
         "Male",
         "27",
         "2018-05-03"
        ],
        [
         "6",
         "8",
         "1995",
         "2.0",
         "81",
         "Berry St at 4th St",
         "80",
         "Townsend St at 5th St",
         "3624",
         "Subscriber",
         "Male",
         "27",
         "2018-07-18"
        ],
        [
         "7",
         "9",
         "1967",
         "3.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "8",
         "The Embarcadero at Vallejo St",
         "4606",
         "Subscriber",
         "Male",
         "26",
         "2017-09-06"
        ],
        [
         "8",
         "10",
         "1983",
         "4.0",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "36",
         "Folsom St at 3rd St",
         "4741",
         "Subscriber",
         "Male",
         "27",
         "2017-06-11"
        ],
        [
         "9",
         "11",
         "1991",
         "9.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "81",
         "Berry St at 4th St",
         "530",
         "Customer",
         "Male",
         "26",
         "2017-03-12"
        ],
        [
         "10",
         "13",
         "1981",
         "5.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "343",
         "Bryant St at 2nd St",
         "5276",
         "Subscriber",
         "Female",
         "27",
         "2017-04-14"
        ],
        [
         "11",
         "15",
         "1983",
         "31.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "5011",
         "Customer",
         "Female",
         "26",
         "2017-01-25"
        ],
        [
         "12",
         "16",
         "1978",
         "4.0",
         "81",
         "Berry St at 4th St",
         "92",
         "Mission Bay Kids Park",
         "236",
         "Subscriber",
         "Female",
         "26",
         "2019-04-19"
        ],
        [
         "13",
         "18",
         "1984",
         "4.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "50",
         "2nd St at Townsend St",
         "5312",
         "Subscriber",
         "Male",
         "26",
         "2017-07-13"
        ],
        [
         "14",
         "21",
         "1993",
         "4.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "343",
         "Bryant St at 2nd St",
         "4762",
         "Subscriber",
         "Male",
         "26",
         "2017-02-14"
        ],
        [
         "15",
         "22",
         "1987",
         "5.0",
         "16",
         "Steuart St at Market St",
         "6",
         "The Embarcadero at Sansome St",
         "5487",
         "Subscriber",
         "Male",
         "27",
         "2019-01-06"
        ],
        [
         "16",
         "24",
         "1979",
         "8.0",
         "16",
         "Steuart St at Market St",
         "49",
         "S Park St at 3rd St",
         "5458",
         "Subscriber",
         "Female",
         "26",
         "2019-06-12"
        ],
        [
         "17",
         "25",
         "1974",
         "11.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "91",
         "Berry St at King St",
         "4597",
         "Subscriber",
         "Male",
         "26",
         "2019-03-01"
        ],
        [
         "18",
         "26",
         "1988",
         "3.0",
         "16",
         "Steuart St at Market St",
         "24",
         "Spear St at Folsom St",
         "4757",
         "Subscriber",
         "Male",
         "26",
         "2017-06-15"
        ],
        [
         "19",
         "29",
         "1988",
         "68.0",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "371",
         "Lombard St at Columbus Ave",
         "4658",
         "Subscriber",
         "Male",
         "26",
         "2017-07-25"
        ],
        [
         "20",
         "31",
         "1995",
         "17.0",
         "22",
         "Howard St at Beale St",
         "356",
         "Valencia St at Clinton Park",
         "5325",
         "Subscriber",
         "Male",
         "26",
         "2019-05-30"
        ],
        [
         "21",
         "32",
         "1995",
         "5.0",
         "81",
         "Berry St at 4th St",
         "104",
         "4th St at 16th St",
         "5030",
         "Subscriber",
         "Female",
         "26",
         "2017-08-19"
        ],
        [
         "22",
         "33",
         "1979",
         "6.0",
         "30",
         "San Francisco Caltrain (Townsend St at 4th St)",
         "59",
         "S Van Ness Ave at Market St",
         "5022",
         "Subscriber",
         "Male",
         "27",
         "2019-07-06"
        ],
        [
         "23",
         "34",
         "1978",
         "9.0",
         "22",
         "Howard St at Beale St",
         "64",
         "5th St at Brannan St",
         "5334",
         "Subscriber",
         "Male",
         "26",
         "2019-07-31"
        ],
        [
         "24",
         "36",
         "1990",
         "14.0",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "91",
         "Berry St at King St",
         "5518",
         "Subscriber",
         "Male",
         "27",
         "2018-06-18"
        ],
        [
         "25",
         "37",
         "1994",
         "8.0",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "58",
         "Market St at 10th St",
         "3225",
         "Subscriber",
         "Male",
         "26",
         "2018-03-16"
        ],
        [
         "26",
         "38",
         "1989",
         "14.0",
         "5",
         "Powell St BART Station (Market St at 5th St)",
         "133",
         "Valencia St at 22nd St",
         "5448",
         "Subscriber",
         "Female",
         "27",
         "2019-08-19"
        ],
        [
         "27",
         "39",
         "1969",
         "13.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "58",
         "Market St at 10th St",
         "5012",
         "Subscriber",
         "Male",
         "26",
         "2019-10-18"
        ],
        [
         "28",
         "40",
         "1991",
         "6.0",
         "30",
         "San Francisco Caltrain (Townsend St at 4th St)",
         "24",
         "Spear St at Folsom St",
         "4711",
         "Subscriber",
         "Male",
         "26",
         "2018-01-31"
        ],
        [
         "29",
         "41",
         "1982",
         "9.0",
         "16",
         "Steuart St at Market St",
         "30",
         "San Francisco Caltrain (Townsend St at 4th St)",
         "4877",
         "Subscriber",
         "Male",
         "26",
         "2019-01-07"
        ],
        [
         "30",
         "42",
         "1971",
         "37.0",
         "5",
         "Powell St BART Station (Market St at 5th St)",
         "324",
         "Union Square (Powell St at Post St)",
         "4934",
         "Subscriber",
         "Male",
         "27",
         "2018-01-09"
        ],
        [
         "31",
         "43",
         "1992",
         "1.0",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "66",
         "3rd St at Townsend St",
         "4947",
         "Subscriber",
         "Male",
         "27",
         "2019-03-14"
        ],
        [
         "32",
         "45",
         "1980",
         "19.0",
         "16",
         "Steuart St at Market St",
         "99",
         "Folsom St at 15th St",
         "4980",
         "Subscriber",
         "Male",
         "27",
         "2018-09-08"
        ],
        [
         "33",
         "46",
         "1982",
         "2.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "25",
         "Howard St at 2nd St",
         "5383",
         "Subscriber",
         "Male",
         "27",
         "2018-01-22"
        ],
        [
         "34",
         "48",
         "1980",
         "4.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "26",
         "1st St at Folsom St",
         "5001",
         "Subscriber",
         "Female",
         "27",
         "2018-02-09"
        ],
        [
         "35",
         "49",
         "1986",
         "8.0",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "37",
         "2nd St at Folsom St",
         "5239",
         "Subscriber",
         "Male",
         "27",
         "2018-09-12"
        ],
        [
         "36",
         "50",
         "1989",
         "8.0",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "58",
         "Market St at 10th St",
         "5477",
         "Subscriber",
         "Male",
         "26",
         "2019-01-18"
        ],
        [
         "37",
         "52",
         "1993",
         "4.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "343",
         "Bryant St at 2nd St",
         "5472",
         "Subscriber",
         "Male",
         "27",
         "2018-05-18"
        ],
        [
         "38",
         "54",
         "1987",
         "9.0",
         "5",
         "Powell St BART Station (Market St at 5th St)",
         "92",
         "Mission Bay Kids Park",
         "5393",
         "Subscriber",
         "Male",
         "26",
         "2018-02-22"
        ],
        [
         "39",
         "55",
         "1985",
         "9.0",
         "3",
         "Powell St BART Station (Market St at 4th St)",
         "115",
         "Jackson Playground",
         "4343",
         "Subscriber",
         "Male",
         "27",
         "2017-08-12"
        ],
        [
         "40",
         "56",
         "1973",
         "11.0",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "58",
         "Market St at 10th St",
         "5267",
         "Subscriber",
         "Male",
         "27",
         "2017-05-20"
        ],
        [
         "41",
         "58",
         "1987",
         "4.0",
         "81",
         "Berry St at 4th St",
         "93",
         "4th St at Mission Bay Blvd S",
         "4638",
         "Subscriber",
         "Male",
         "26",
         "2017-05-02"
        ],
        [
         "42",
         "59",
         "1995",
         "6.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "6",
         "The Embarcadero at Sansome St",
         "5364",
         "Subscriber",
         "Female",
         "27",
         "2017-07-02"
        ],
        [
         "43",
         "60",
         "1989",
         "6.0",
         "67",
         "San Francisco Caltrain Station 2  (Townsend St at 4th St)",
         "88",
         "11th St at Bryant St",
         "4597",
         "Subscriber",
         "Male",
         "26",
         "2018-04-22"
        ],
        [
         "44",
         "61",
         "1985",
         "7.0",
         "81",
         "Berry St at 4th St",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "5227",
         "Subscriber",
         "Female",
         "27",
         "2020-01-17"
        ],
        [
         "45",
         "62",
         "1972",
         "1.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "16",
         "Steuart St at Market St",
         "2926",
         "Subscriber",
         "Male",
         "26",
         "2018-02-24"
        ],
        [
         "46",
         "63",
         "1986",
         "10.0",
         "21",
         "Montgomery St BART Station (Market St at 2nd St)",
         "81",
         "Berry St at 4th St",
         "4383",
         "Subscriber",
         "Male",
         "27",
         "2018-10-27"
        ],
        [
         "47",
         "64",
         "1978",
         "6.0",
         "30",
         "San Francisco Caltrain (Townsend St at 4th St)",
         "22",
         "Howard St at Beale St",
         "1896",
         "Subscriber",
         "Male",
         "27",
         "2018-11-08"
        ],
        [
         "48",
         "65",
         "1987",
         "8.0",
         "15",
         "San Francisco Ferry Building (Harry Bridges Plaza)",
         "66",
         "3rd St at Townsend St",
         "5138",
         "Subscriber",
         "Female",
         "26",
         "2018-08-31"
        ],
        [
         "49",
         "66",
         "1989",
         "16.0",
         "30",
         "San Francisco Caltrain (Townsend St at 4th St)",
         "14",
         "Clay St at Battery St",
         "4445",
         "Subscriber",
         "Male",
         "26",
         "2019-02-27"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 74
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>user_birth_year</th>\n",
       "      <th>duration</th>\n",
       "      <th>station_A_id</th>\n",
       "      <th>station_A_name</th>\n",
       "      <th>station_B_id</th>\n",
       "      <th>station_B_name</th>\n",
       "      <th>bike_id</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>tire_sizes</th>\n",
       "      <th>ride_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Steuart St at Market St</td>\n",
       "      <td>93</td>\n",
       "      <td>4th St at Mission Bay Blvd S</td>\n",
       "      <td>5504</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1988</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Powell St BART Station (Market St at 4th St)</td>\n",
       "      <td>93</td>\n",
       "      <td>4th St at Mission Bay Blvd S</td>\n",
       "      <td>2915</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1988</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15</td>\n",
       "      <td>San Francisco Ferry Building (Harry Bridges Pl...</td>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>5340</td>\n",
       "      <td>Customer</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>2019-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1969</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Montgomery St BART Station (Market St at 2nd St)</td>\n",
       "      <td>50</td>\n",
       "      <td>2nd St at Townsend St</td>\n",
       "      <td>746</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1986</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81</td>\n",
       "      <td>Berry St at 4th St</td>\n",
       "      <td>21</td>\n",
       "      <td>Montgomery St BART Station (Market St at 2nd St)</td>\n",
       "      <td>5477</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>94</td>\n",
       "      <td>1993</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Montgomery St BART Station (Market St at 2nd St)</td>\n",
       "      <td>119</td>\n",
       "      <td>18th St at Noe St</td>\n",
       "      <td>532</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2019-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>95</td>\n",
       "      <td>1959</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30</td>\n",
       "      <td>San Francisco Caltrain (Townsend St at 4th St)</td>\n",
       "      <td>14</td>\n",
       "      <td>Clay St at Battery St</td>\n",
       "      <td>2047</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>96</td>\n",
       "      <td>1991</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Howard St at Beale St</td>\n",
       "      <td>30</td>\n",
       "      <td>San Francisco Caltrain (Townsend St at 4th St)</td>\n",
       "      <td>5417</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>98</td>\n",
       "      <td>1989</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67</td>\n",
       "      <td>San Francisco Caltrain Station 2  (Townsend St...</td>\n",
       "      <td>13</td>\n",
       "      <td>Commercial St at Montgomery St</td>\n",
       "      <td>1846</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>99</td>\n",
       "      <td>1968</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30</td>\n",
       "      <td>San Francisco Caltrain (Townsend St at 4th St)</td>\n",
       "      <td>14</td>\n",
       "      <td>Clay St at Battery St</td>\n",
       "      <td>1194</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-11-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ride_id  user_birth_year  duration  station_A_id  \\\n",
       "0         0             1988      11.0            16   \n",
       "1         1             1988       8.0             3   \n",
       "2         2             1988      11.0            15   \n",
       "3         3             1969       7.0            21   \n",
       "4         4             1986      11.0            81   \n",
       "..      ...              ...       ...           ...   \n",
       "69       94             1993      25.0            21   \n",
       "70       95             1959      11.0            30   \n",
       "71       96             1991       7.0            22   \n",
       "72       98             1989      21.0            67   \n",
       "73       99             1968      15.0            30   \n",
       "\n",
       "                                       station_A_name  station_B_id  \\\n",
       "0                             Steuart St at Market St            93   \n",
       "1        Powell St BART Station (Market St at 4th St)            93   \n",
       "2   San Francisco Ferry Building (Harry Bridges Pl...            67   \n",
       "3    Montgomery St BART Station (Market St at 2nd St)            50   \n",
       "4                                  Berry St at 4th St            21   \n",
       "..                                                ...           ...   \n",
       "69   Montgomery St BART Station (Market St at 2nd St)           119   \n",
       "70     San Francisco Caltrain (Townsend St at 4th St)            14   \n",
       "71                              Howard St at Beale St            30   \n",
       "72  San Francisco Caltrain Station 2  (Townsend St...            13   \n",
       "73     San Francisco Caltrain (Townsend St at 4th St)            14   \n",
       "\n",
       "                                       station_B_name  bike_id   user_type  \\\n",
       "0                        4th St at Mission Bay Blvd S     5504  Subscriber   \n",
       "1                        4th St at Mission Bay Blvd S     2915  Subscriber   \n",
       "2   San Francisco Caltrain Station 2  (Townsend St...     5340    Customer   \n",
       "3                               2nd St at Townsend St      746  Subscriber   \n",
       "4    Montgomery St BART Station (Market St at 2nd St)     5477  Subscriber   \n",
       "..                                                ...      ...         ...   \n",
       "69                                  18th St at Noe St      532  Subscriber   \n",
       "70                              Clay St at Battery St     2047  Subscriber   \n",
       "71     San Francisco Caltrain (Townsend St at 4th St)     5417  Subscriber   \n",
       "72                     Commercial St at Montgomery St     1846  Subscriber   \n",
       "73                              Clay St at Battery St     1194  Subscriber   \n",
       "\n",
       "   user_gender  tire_sizes   ride_date  \n",
       "0         Male          27  2018-03-04  \n",
       "1         Male          27  2017-03-27  \n",
       "2         Male          26  2019-06-30  \n",
       "3         Male          27  2018-11-16  \n",
       "4         Male          26  2017-11-01  \n",
       "..         ...         ...         ...  \n",
       "69        Male          27  2019-12-06  \n",
       "70        Male          27  2018-12-22  \n",
       "71        Male          27  2017-06-30  \n",
       "72        Male          27  2018-12-10  \n",
       "73        Male          27  2018-11-11  \n",
       "\n",
       "[74 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ride_sharing_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb25bf",
   "metadata": {},
   "source": [
    "## Uniqueness Constraints\n",
    "\n",
    "### Introduction to Uniqueness Constraints\n",
    "\n",
    "**Uniqueness constraints** ensure that data values within specified columns or across an entire dataset do not repeat. They maintain data integrity by guaranteeing that each entry is distinct, which is critical for accurate analysis, database indexing, and building reliable models.\n",
    "\n",
    "### Why are Uniqueness Constraints Important?\n",
    "\n",
    "- **Data integrity:** Ensuring every record is unique prevents ambiguous entries that could lead to incorrect analysis or duplication errors.\n",
    "- **Database normalization:** Unique constraints form the backbone of database normalization, improving efficiency and query performance.\n",
    "- **Reliable analyses:** Uniqueness ensures reliable statistical insights by eliminating duplicated data points, avoiding skewed or misleading results.\n",
    "\n",
    "### Identifying Duplicate Values\n",
    "\n",
    "Duplicate rows occur when multiple records contain identical values across one or more columns.\n",
    "\n",
    "#### Checking for duplicates in pandas:\n",
    "\n",
    "The `.duplicated()` method identifies duplicated rows.\n",
    "\n",
    "```python\n",
    "# Identify duplicates (default checks all columns)\n",
    "duplicates = df.duplicated()\n",
    "print(duplicates.head())\n",
    "```\n",
    "\n",
    "#### Retrieving duplicate rows:\n",
    "\n",
    "```python\n",
    "# Fetch duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "print(duplicate_rows)\n",
    "```\n",
    "\n",
    "#### Specifying columns to find duplicates:\n",
    "\n",
    "Use the `subset` parameter to specify which columns determine uniqueness.\n",
    "\n",
    "```python\n",
    "duplicates = df.duplicated(subset=['column1', 'column2'], keep=False)\n",
    "df[duplicates]\n",
    "```\n",
    "\n",
    "#### Parameters of `.duplicated()`:\n",
    "\n",
    "- `subset`: List of column names to check for duplicates.\n",
    "- `keep`:\n",
    "  - `'first'`: Marks duplicates as True except the first occurrence.\n",
    "  - `'last'`: Marks duplicates as True except the last occurrence.\n",
    "  - `False`: Marks all duplicate rows as True.\n",
    "\n",
    "### Resolving Duplicate Entries\n",
    "\n",
    "#### Method 1: Dropping Duplicates (`.drop_duplicates()`):\n",
    "\n",
    "The simplest method for resolving duplicate entries.\n",
    "\n",
    "```python\n",
    "# Drop duplicates (in-place operation)\n",
    "df.drop_duplicates(inplace=True)\n",
    "```\n",
    "\n",
    "Specifying columns to target specific duplicates:\n",
    "\n",
    "```python\n",
    "df.drop_duplicates(subset=['column1', 'column2'], keep='first', inplace=True)\n",
    "```\n",
    "\n",
    "#### Method 2: Grouping and Aggregation (`groupby` & `agg`):\n",
    "\n",
    "Useful when duplicate rows contain numeric data that can be meaningfully aggregated.\n",
    "\n",
    "```python\n",
    "# Aggregate duplicates with statistical summaries\n",
    "df_cleaned = df.groupby(['column1', 'column2']).agg({\n",
    "    'numeric_col1': 'mean',\n",
    "    'numeric_col2': 'max'\n",
    "}).reset_index()\n",
    "```\n",
    "\n",
    "### Validating Uniqueness with Assertions\n",
    "\n",
    "After handling duplicates, use `assert` statements to verify uniqueness:\n",
    "\n",
    "```python\n",
    "assert df.duplicated().sum() == 0, \"There are still duplicates!\"\n",
    "```\n",
    "\n",
    "### Pythonic Approaches to Managing Uniqueness\n",
    "\n",
    "#### Efficient Duplicate Checks with Sets\n",
    "\n",
    "In Python, sets inherently enforce uniqueness:\n",
    "\n",
    "```python\n",
    "# Checking uniqueness using sets\n",
    "assert len(df['id_column']) == len(set(df['id_column'])), \"Duplicate IDs found!\"\n",
    "```\n",
    "\n",
    "### Using `.isin()` for identifying duplicates in another DataFrame:\n",
    "\n",
    "For cross-dataset duplicate checking (common in data merging):\n",
    "\n",
    "```python\n",
    "duplicates = df1[df1['id'].isin(df2['id'])]\n",
    "```\n",
    "\n",
    "#### Merging DataFrames to Identify Common and Unique Rows:\n",
    "\n",
    "Use `merge` operations explicitly to handle duplicates when joining datasets.\n",
    "\n",
    "- **Inner Join:** Identify common records\n",
    "```python\n",
    "common_rows = pd.merge(df1, df2, on='id', how='inner')\n",
    "```\n",
    "\n",
    "- **Anti Join:** Identify rows unique to one DataFrame\n",
    "```python\n",
    "unique_to_df1 = df1[~df1['id'].isin(df2['id'])]\n",
    "```\n",
    "### Visualization of Duplicate Data (Optional but Insightful)\n",
    "\n",
    "Visualizing duplicates can highlight problems clearly, especially in large datasets.\n",
    "\n",
    "#### Counting and Plotting Duplicate Occurrences\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count occurrences\n",
    "duplicate_counts = df['id_column'].value_counts()\n",
    "\n",
    "# Plot duplicates distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.histplot(duplicate_counts, bins=20, kde=False, ax=ax)\n",
    "ax.set_title('Distribution of Duplicate Counts')\n",
    "ax.set_xlabel('Number of Duplicates')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "\n",
    "### Key Strategies and Recommendations:\n",
    "\n",
    "- **Regularly validate uniqueness constraints**: Integrate into data processing pipelines with assertions.\n",
    "- **Clearly define columns for uniqueness checks**: Consistency in identifying duplicates.\n",
    "- **Aggregate numerical duplicates meaningfully**: Use `.groupby()` & `.agg()` to retain valuable information rather than simple drops.\n",
    "- **Understand dataset merging implications**: Clearly distinguish between inner, outer, and anti joins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea68073e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "airline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "destination",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "boarding_area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dept_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wait_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cleanliness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "satisfaction",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "145f2305-4e68-4d9a-8390-3cd77e6298dd",
       "rows": [
        [
         "0",
         "1351",
         "Tuesday",
         "UNITED INTL",
         "KANSAI",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "115.0",
         "Clean",
         "Neutral",
         "Very satisfied"
        ],
        [
         "1",
         "373",
         "Friday",
         "ALASKA",
         "SAN JOSE DEL CABO",
         "Canada/Mexico",
         "Small",
         "Gates 50-59",
         "2018-12-31",
         "135.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "2",
         "2820",
         "Thursday",
         "DELTA",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "70.0000000000001",
         "Average",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "3",
         "1157",
         "Tuesday",
         "SOUTHWEST",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "190.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "4",
         "2992",
         "Wednesday",
         "AMERICAN",
         "MIAMI",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "559.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        day      airline        destination    dest_region dest_size  \\\n",
       "0  1351    Tuesday  UNITED INTL             KANSAI           Asia       Hub   \n",
       "1   373     Friday       ALASKA  SAN JOSE DEL CABO  Canada/Mexico     Small   \n",
       "2  2820   Thursday        DELTA        LOS ANGELES        West US       Hub   \n",
       "3  1157    Tuesday    SOUTHWEST        LOS ANGELES        West US       Hub   \n",
       "4  2992  Wednesday     AMERICAN              MIAMI        East US       Hub   \n",
       "\n",
       "  boarding_area   dept_time  wait_min     cleanliness         safety  \\\n",
       "0  Gates 91-102  2018-12-31     115.0           Clean        Neutral   \n",
       "1   Gates 50-59  2018-12-31     135.0           Clean      Very safe   \n",
       "2   Gates 40-48  2018-12-31      70.0         Average  Somewhat safe   \n",
       "3   Gates 20-39  2018-12-31     190.0           Clean      Very safe   \n",
       "4   Gates 50-59  2018-12-31     559.0  Somewhat clean      Very safe   \n",
       "\n",
       "         satisfaction  \n",
       "0      Very satisfied  \n",
       "1      Very satisfied  \n",
       "2             Neutral  \n",
       "3  Somewhat satsified  \n",
       "4  Somewhat satsified  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://assets.datacamp.com/production/repositories/5737/datasets/ba95dfa6d750e4bf2ddda2349cfe0af80ab765ff/airlines_final.csv\"\n",
    "airlines = pd.read_csv(url, usecols=lambda col: not col.startswith(\"Unnamed\"))\n",
    "airlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c385dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cleanliness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "satisfaction",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8cd5eb1d-9d89-4a7b-8f4c-baeb598c6767",
       "rows": [
        [
         "0",
         "Clean",
         "Neutral",
         "Very satisfied"
        ],
        [
         "1",
         "Average",
         "Very safe",
         "Neutral"
        ],
        [
         "2",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satisfied"
        ],
        [
         "3",
         "Somewhat dirty",
         "Very unsafe",
         "Somewhat unsatisfied"
        ],
        [
         "4",
         "Dirty",
         "Somewhat unsafe",
         "Very unsatisfied"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Somewhat dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Somewhat unsatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty</td>\n",
       "      <td>Somewhat unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cleanliness           safety          satisfaction\n",
       "0           Clean          Neutral        Very satisfied\n",
       "1         Average        Very safe               Neutral\n",
       "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
       "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
       "4           Dirty  Somewhat unsafe      Very unsatisfied"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = {\n",
    "    \"cleanliness\": {\n",
    "        0: \"Clean\",\n",
    "        1: \"Average\",\n",
    "        2: \"Somewhat clean\",\n",
    "        3: \"Somewhat dirty\",\n",
    "        4: \"Dirty\",\n",
    "    },\n",
    "    \"safety\": {\n",
    "        0: \"Neutral\",\n",
    "        1: \"Very safe\",\n",
    "        2: \"Somewhat safe\",\n",
    "        3: \"Very unsafe\",\n",
    "        4: \"Somewhat unsafe\",\n",
    "    },\n",
    "    \"satisfaction\": {\n",
    "        0: \"Very satisfied\",\n",
    "        1: \"Neutral\",\n",
    "        2: \"Somewhat satisfied\",\n",
    "        3: \"Somewhat unsatisfied\",\n",
    "        4: \"Very unsatisfied\",\n",
    "    },\n",
    "}\n",
    "\n",
    "categories = pd.DataFrame(cat)\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1130c41",
   "metadata": {},
   "source": [
    "The DataCamp instructor required me to revisit the cleanliness category because it did not include the value \"Neutral.\" I still do not understand the rationale, as the exercise seemed unproductive and yielded no tangible outcomes by the end of the chapter. Meanwhile, the Satisfaction category contained the value `'Somewhat satsified'`, yet there was no suggestion to address or correct it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f27d92a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent values found in 'satisfaction': {'Somewhat satsified'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each column in the 'categories' DataFrame\n",
    "for col in categories.columns:\n",
    "\n",
    "    # Get the unique values from the airline data for the current column\n",
    "    airline_categories = set(airlines[col].unique())\n",
    "\n",
    "    # Get the standard-defined categories, dropping any potential NaN values\n",
    "    standard_categories = set(categories[col].dropna().unique())\n",
    "\n",
    "    # Find the values present in the airline data but not in the standard\n",
    "    discrepancies = airline_categories.difference(standard_categories)\n",
    "\n",
    "    # If the set of discrepancies is not empty, print a report for that column\n",
    "    if discrepancies:\n",
    "        print(f\"Inconsistent values found in '{col}': {discrepancies}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c8784",
   "metadata": {},
   "source": [
    "Here I tried to perform the same instructions and techniques to fix the `'Somewhat satsified'` inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e9d2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Somewhat satsified'}\n"
     ]
    }
   ],
   "source": [
    "# Find the satisfaction category in airlines that is not in the standard categories\n",
    "inconsistent_satisfaction = set(airlines[\"satisfaction\"]).difference(\n",
    "    categories[\"satisfaction\"]\n",
    ")\n",
    "print(inconsistent_satisfaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62626647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "airline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "destination",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "boarding_area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dept_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wait_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cleanliness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "satisfaction",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ed87c752-656d-4eed-9d7b-80163a64ffe9",
       "rows": [
        [
         "3",
         "1157",
         "Tuesday",
         "SOUTHWEST",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "190.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "4",
         "2992",
         "Wednesday",
         "AMERICAN",
         "MIAMI",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "559.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "6",
         "2578",
         "Saturday",
         "JETBLUE",
         "LONG BEACH",
         "West US",
         "Small",
         "Gates 1-12",
         "2018-12-31",
         "62.99999999999989",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "8",
         "919",
         "Friday",
         "AIR CANADA",
         "TORONTO",
         "Canada/Mexico",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "70.0000000000001",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "10",
         "1129",
         "Tuesday",
         "SOUTHWEST",
         "SAN DIEGO",
         "West US",
         "Medium",
         "Gates 20-39",
         "2018-12-31",
         "540.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "11",
         "2648",
         "Saturday",
         "JETBLUE",
         "BOSTON",
         "East US",
         "Large",
         "Gates 1-12",
         "2018-12-31",
         "192.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "12",
         "3104",
         "Tuesday",
         "UNITED",
         "SPOKANE",
         "West US",
         "Small",
         "Gates 70-90",
         "2018-12-31",
         "107.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "13",
         "2589",
         "Saturday",
         "INTERJET",
         "GUADALAJARA",
         "Canada/Mexico",
         "Medium",
         "Gates 1-12",
         "2018-12-31",
         "155.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "14",
         "2345",
         "Tuesday",
         "DELTA",
         "MINNEAPOLIS-ST. PAUL",
         "Midwest US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "155.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "15",
         "390",
         "Friday",
         "ALASKA",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "175.0",
         "Somewhat clean",
         "Neutral",
         "Somewhat satsified"
        ],
        [
         "17",
         "2913",
         "Friday",
         "TURKISH AIRLINES",
         "ISTANBUL",
         "Middle East",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "225.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "19",
         "767",
         "Thursday",
         "AIR CANADA",
         "TORONTO",
         "Canada/Mexico",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "115.0",
         "Average",
         "Neutral",
         "Somewhat satsified"
        ],
        [
         "20",
         "1214",
         "Tuesday",
         "SOUTHWEST",
         "LAS VEGAS",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "59.99999999999989",
         "Average",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "21",
         "1373",
         "Tuesday",
         "UNITED INTL",
         "SHANGHAI",
         "Asia",
         "Hub     ",
         "Gates 91-102",
         "2018-12-31",
         "145.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "23",
         "2723",
         "Wednesday",
         "AIR FRANCE/KLM",
         "PARIS-DE GAULLE",
         "Europe",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "160.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "25",
         "214",
         "Wednesday",
         "AMERICAN",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "100.0",
         "Average",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "26",
         "1372",
         "Tuesday",
         "UNITED INTL",
         "PARIS-DE GAULLE",
         "eur",
         "    Hub",
         "Gates 91-102",
         "2018-12-31",
         "205.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "27",
         "1956",
         "Tuesday",
         "UNITED",
         "BOSTON",
         "East US",
         "Large",
         "Gates 70-90",
         "2018-12-31",
         "115.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "29",
         "1487",
         "Wednesday",
         "HAWAIIAN AIR",
         "HONOLULU",
         "West US",
         "Medium     ",
         "Gates 1-12",
         "2018-12-31",
         "135.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "30",
         "842",
         "Tuesday",
         "AMERICAN",
         "DALLAS-FT. WORTH",
         "Midwest US",
         "    Hub",
         "Gates 50-59",
         "2018-12-31",
         "145.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "31",
         "930",
         "Friday",
         "AIR CANADA",
         "TORONTO",
         "Canada/Mexico",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "270.0",
         "Average",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "33",
         "743",
         "Sunday",
         "ALASKA",
         "NEW YORK-JFK",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "100.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "35",
         "315",
         "Thursday",
         "UNITED",
         "SAN DIEGO",
         "West US",
         "Medium",
         "Gates 70-90",
         "2018-12-31",
         "92.0000000000002",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "38",
         "2890",
         "Sunday",
         "WOW",
         "REYKJAVIK",
         "Europe",
         "Small",
         "Gates 1-12",
         "2018-12-31",
         "145.0",
         "Average",
         "Neutral",
         "Somewhat satsified"
        ],
        [
         "40",
         "3183",
         "Thursday",
         "DELTA",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "900.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "42",
         "2740",
         "Wednesday",
         "AIR FRANCE/KLM",
         "PARIS-DE GAULLE",
         "eur",
         "    Hub",
         "Gates 1-12",
         "2018-12-31",
         "330.0",
         "Average",
         "Very unsafe",
         "Somewhat satsified"
        ],
        [
         "43",
         "1570",
         "Wednesday",
         "UNITED INTL",
         "HONG KONG",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "150.0",
         "Clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "44",
         "3228",
         "Thursday",
         "ALASKA",
         "PORTLAND",
         "West US",
         "Medium",
         "Gates 50-59",
         "2018-12-31",
         "110.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "45",
         "1140",
         "Tuesday",
         "SOUTHWEST",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "415.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "50",
         "1139",
         "Tuesday",
         "SOUTHWEST",
         "SAN DIEGO",
         "West US",
         "Medium",
         "Gates 20-39",
         "2018-12-31",
         "120.0",
         "Average",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "52",
         "558",
         "Thursday",
         "EMIRATES",
         "DUBAI",
         "Middle East",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "225.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "53",
         "262",
         "Friday",
         "AIR CANADA",
         "TORONTO",
         "Canada/Mexico",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "175.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "55",
         "1713",
         "Sunday",
         "AIR FRANCE/KLM",
         "PARIS-DE GAULLE",
         "Europe",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "135.0",
         "Average",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "56",
         "407",
         "Saturday",
         "UNITED",
         "PHOENIX",
         "West US",
         "Hub",
         "Gates 70-90",
         "2018-12-31",
         "110.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "62",
         "2400",
         "Wednesday",
         "UNITED INTL",
         "BEIJING",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "205.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "64",
         "2865",
         "Wednesday",
         "UNITED",
         "WASHINGTON DC-DULLES",
         "East US",
         "Medium",
         "Gates 70-90",
         "2018-12-31",
         "77.0",
         "Average",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "66",
         "1957",
         "Friday",
         "CATHAY PACIFIC",
         "HONG KONG",
         "Asia",
         "Hub     ",
         "Gates 1-12",
         "2018-12-31",
         "185.0",
         "Somewhat clean",
         "Neutral",
         "Somewhat satsified"
        ],
        [
         "67",
         "2526",
         "Tuesday",
         "JETBLUE",
         "LONG BEACH",
         "West US",
         "Small",
         "Gates 1-12",
         "2018-12-31",
         "60.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "68",
         "3041",
         "Tuesday",
         "AMERICAN",
         "DALLAS-FT. WORTH",
         "Midwest US",
         "    Hub",
         "Gates 50-59",
         "2018-12-31",
         "185.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "69",
         "813",
         "Sunday",
         "ALASKA",
         "PORTLAND",
         "West US",
         "Medium",
         "Gates 50-59",
         "2018-12-31",
         "140.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "70",
         "1523",
         "Wednesday",
         "JETBLUE",
         "NEW YORK-JFK",
         "EAST US",
         "    Hub",
         "Gates 1-12",
         "2018-12-31",
         "81.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "71",
         "2796",
         "Sunday",
         "WOW",
         "REYKJAVIK",
         "Europe",
         "Small",
         "Gates 1-12",
         "2018-12-31",
         "160.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "73",
         "2042",
         "Friday",
         "BRITISH AIRWAYS",
         "LONDON HEATHROW",
         "Europe",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "180.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "74",
         "3062",
         "Sunday",
         "PHILIPPINE AIRLINES",
         "MANILA",
         "Asia",
         "Medium",
         "Gates 1-12",
         "2018-01-01",
         "215.0",
         "Clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "75",
         "2026",
         "Friday",
         "BRITISH AIRWAYS",
         "LONDON HEATHROW",
         "Europe",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "120.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "76",
         "1793",
         "Saturday",
         "UNITED",
         "RALEIGH-DURHAM",
         "East US",
         "Medium",
         "Gates 70-90",
         "2018-12-31",
         "150.0",
         "Clean",
         "Somewhat safe",
         "Somewhat satsified"
        ],
        [
         "77",
         "1366",
         "Tuesday",
         "UNITED INTL",
         "KANSAI",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "170.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "78",
         "1017",
         "Friday",
         "AIR CANADA",
         "VANCOUVER",
         "Canada/Mexico",
         "Medium",
         "Gates 91-102",
         "2018-12-31",
         "110.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "79",
         "2501",
         "Friday",
         "ALASKA",
         "SALT LAKE CITY",
         "West US",
         "    Medium",
         "Gates 1-12",
         "2018-12-31",
         "120.0",
         "Somewhat clean",
         "Neutral",
         "Somewhat satsified"
        ],
        [
         "80",
         "3202",
         "Sunday",
         "CATHAY PACIFIC",
         "HONG KONG",
         "Asia",
         "Hub",
         "Gates 1-12",
         "2018-01-01",
         "210.0",
         "Clean",
         "Neutral",
         "Somewhat satsified"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 1349
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2578</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>JETBLUE</td>\n",
       "      <td>LONG BEACH</td>\n",
       "      <td>West US</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>919</td>\n",
       "      <td>Friday</td>\n",
       "      <td>AIR CANADA</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1129</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>West US</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>540.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1942</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED</td>\n",
       "      <td>BOSTON</td>\n",
       "      <td>EAST US</td>\n",
       "      <td>Large</td>\n",
       "      <td>Gates 70-90</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>145.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>2130</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>CATHAY PACIFIC</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>380.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2888</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>UNITED</td>\n",
       "      <td>AUSTIN</td>\n",
       "      <td>Midwest US</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Gates 70-90</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Somewhat unsafe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>1475</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NEW YORK-JFK</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>280.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>2162</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>CHINA EASTERN</td>\n",
       "      <td>QINGDAO</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Large</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>220.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1349 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        day         airline   destination    dest_region  dest_size  \\\n",
       "3     1157    Tuesday       SOUTHWEST   LOS ANGELES        West US        Hub   \n",
       "4     2992  Wednesday        AMERICAN         MIAMI        East US        Hub   \n",
       "6     2578   Saturday         JETBLUE    LONG BEACH        West US      Small   \n",
       "8      919     Friday      AIR CANADA       TORONTO  Canada/Mexico        Hub   \n",
       "10    1129    Tuesday       SOUTHWEST     SAN DIEGO        West US     Medium   \n",
       "...    ...        ...             ...           ...            ...        ...   \n",
       "2468  1942    Tuesday          UNITED        BOSTON        EAST US      Large   \n",
       "2469  2130   Thursday  CATHAY PACIFIC     HONG KONG           Asia        Hub   \n",
       "2471  2888  Wednesday          UNITED        AUSTIN     Midwest US     Medium   \n",
       "2472  1475    Tuesday          ALASKA  NEW YORK-JFK        East US        Hub   \n",
       "2476  2162   Saturday   CHINA EASTERN       QINGDAO           Asia      Large   \n",
       "\n",
       "     boarding_area   dept_time  wait_min     cleanliness           safety  \\\n",
       "3      Gates 20-39  2018-12-31     190.0           Clean        Very safe   \n",
       "4      Gates 50-59  2018-12-31     559.0  Somewhat clean        Very safe   \n",
       "6       Gates 1-12  2018-12-31      63.0           Clean        Very safe   \n",
       "8     Gates 91-102  2018-12-31      70.0  Somewhat clean    Somewhat safe   \n",
       "10     Gates 20-39  2018-12-31     540.0           Clean        Very safe   \n",
       "...            ...         ...       ...             ...              ...   \n",
       "2468   Gates 70-90  2018-12-31     145.0  Somewhat clean    Somewhat safe   \n",
       "2469    Gates 1-12  2018-12-31     380.0  Somewhat clean    Somewhat safe   \n",
       "2471   Gates 70-90  2018-12-31      60.0  Somewhat clean  Somewhat unsafe   \n",
       "2472   Gates 50-59  2018-12-31     280.0  Somewhat clean          Neutral   \n",
       "2476    Gates 1-12  2018-12-31     220.0           Clean        Very safe   \n",
       "\n",
       "            satisfaction  \n",
       "3     Somewhat satsified  \n",
       "4     Somewhat satsified  \n",
       "6     Somewhat satsified  \n",
       "8     Somewhat satsified  \n",
       "10    Somewhat satsified  \n",
       "...                  ...  \n",
       "2468  Somewhat satsified  \n",
       "2469  Somewhat satsified  \n",
       "2471  Somewhat satsified  \n",
       "2472  Somewhat satsified  \n",
       "2476  Somewhat satsified  \n",
       "\n",
       "[1349 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all rows where the 'satisfaction' column has the inconsistent value\n",
    "inconsistent_rows = airlines[\"satisfaction\"].isin(inconsistent_satisfaction)\n",
    "display(airlines[inconsistent_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f93673c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "airline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "destination",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "boarding_area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dept_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wait_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cleanliness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "satisfaction",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "589b473f-f785-4b44-bc47-09cffbd98b66",
       "rows": [
        [
         "0",
         "1351",
         "Tuesday",
         "UNITED INTL",
         "KANSAI",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "115.0",
         "Clean",
         "Neutral",
         "Very satisfied"
        ],
        [
         "1",
         "373",
         "Friday",
         "ALASKA",
         "SAN JOSE DEL CABO",
         "Canada/Mexico",
         "Small",
         "Gates 50-59",
         "2018-12-31",
         "135.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "2",
         "2820",
         "Thursday",
         "DELTA",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "70.0000000000001",
         "Average",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "5",
         "634",
         "Thursday",
         "ALASKA",
         "NEWARK",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "140.0",
         "Somewhat clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "7",
         "2592",
         "Saturday",
         "AEROMEXICO",
         "MEXICO CITY",
         "Canada/Mexico",
         "    Hub",
         "Gates 1-12",
         "2018-12-31",
         "215.0",
         "Somewhat clean",
         "Very safe",
         "Neutral"
        ],
        [
         "9",
         "3028",
         "Tuesday",
         "UNITED",
         "PORTLAND",
         "West US",
         "Medium",
         "Gates 70-90",
         "2018-12-31",
         "180.0",
         "Average",
         "Very safe",
         "Neutral"
        ],
        [
         "16",
         "954",
         "Tuesday",
         "ALASKA",
         "NEW YORK-JFK",
         "EAST US",
         "    Hub",
         "Gates 50-59",
         "2018-12-31",
         "100.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "18",
         "803",
         "Sunday",
         "ALASKA",
         "BALTIMORE",
         "East US",
         "Medium",
         "Gates 50-59",
         "2018-12-31",
         "155.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "22",
         "1263",
         "Thursday",
         "UNITED INTL",
         "TOKYO-NARITA",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "210.0",
         "Average",
         "Neutral",
         "Neutral"
        ],
        [
         "24",
         "3097",
         "Tuesday",
         "UNITED",
         "SPOKANE",
         "West US",
         "    Small",
         "Gates 70-90",
         "2018-12-31",
         "604.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "28",
         "1716",
         "Sunday",
         "AIR FRANCE/KLM",
         "PARIS-DE GAULLE",
         "Europe",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "510.0",
         "Clean",
         "Neutral",
         "Very satisfied"
        ],
        [
         "32",
         "3064",
         "Sunday",
         "COPA",
         "PANAMA CITY",
         "Central/South America",
         "Medium",
         "Gates 1-12",
         "2018-12-31",
         "173.0",
         "Average",
         "Neutral",
         "Neutral"
        ],
        [
         "34",
         "2099",
         "Monday",
         "UNITED INTL",
         "MEXICO CITY",
         "Canada/Mexico",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "190.0",
         "Clean",
         "Very safe",
         "Neutral"
        ],
        [
         "36",
         "2216",
         "Thursday",
         "SOUTHWEST",
         "PHOENIX",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "135.0",
         "Somewhat clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "37",
         "3121",
         "Sunday",
         "ALASKA",
         "NEWARK",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "125.0",
         "Clean",
         "Very safe",
         "Neutral"
        ],
        [
         "39",
         "3046",
         "Tuesday",
         "AMERICAN",
         "LOS ANGELES",
         "West US",
         "Hub     ",
         "Gates 50-59",
         "2018-12-31",
         "120.0",
         "Average",
         "Very safe",
         "Very satisfied"
        ],
        [
         "41",
         "2288",
         "Tuesday",
         "UNITED",
         "SAN ANTONIO",
         "Midwest US",
         "    Medium",
         "Gates 70-90",
         "2018-12-31",
         "150.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "46",
         "349",
         "Friday",
         "ALASKA",
         "SAN DIEGO",
         "West US",
         "Medium",
         "Gates 50-59",
         "2018-12-31",
         "76.0000000000001",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "47",
         "1572",
         "Wednesday",
         "UNITED INTL",
         "HONG KONG",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "150.0",
         "Somewhat clean",
         "Neutral",
         "Very satisfied"
        ],
        [
         "48",
         "1635",
         "Thursday",
         "KOREAN AIR",
         "SEOUL",
         "Asia",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "210.0",
         "Somewhat dirty",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "49",
         "524",
         "Thursday",
         "EMIRATES",
         "DUBAI",
         "Middle East",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "165.0",
         "Somewhat clean",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "51",
         "314",
         "Thursday",
         "UNITED",
         "SAN DIEGO",
         "West US",
         "Medium",
         "Gates 70-90",
         "2018-12-31",
         "122.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "54",
         "2537",
         "Tuesday",
         "UNITED",
         "CHICAGO-O'HARE",
         "Midwest US",
         "    Hub",
         "Gates 60-69",
         "2018-12-31",
         "115.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "57",
         "3212",
         "Thursday",
         "AMERICAN",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "90.0",
         "Somewhat clean",
         "Somewhat safe",
         "Somewhat unsatisfied"
        ],
        [
         "58",
         "450",
         "Sunday",
         "UNITED",
         "INDIANAPOLIS",
         "Midwest US",
         "Medium",
         "Gates 60-69",
         "2018-12-31",
         "67.9999999999999",
         "Clean",
         "Somewhat safe",
         "Very satisfied"
        ],
        [
         "59",
         "1477",
         "Wednesday",
         "AVIANCA",
         "SAN SALVADOR",
         "Central/South America",
         "Small",
         "Gates 1-12",
         "2018-12-31",
         "155.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "60",
         "3151",
         "Thursday",
         "DELTA",
         "SALT LAKE CITY",
         "West US",
         "Medium",
         "Gates 40-48",
         "2018-12-31",
         "14.9999999999999",
         "Average",
         "Very safe",
         "Neutral"
        ],
        [
         "61",
         "2257",
         "Wednesday",
         "UNITED",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 60-69",
         "2018-12-31",
         "64.9999999999999",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "63",
         "2230",
         "Wednesday",
         "AER LINGUS",
         "DUBLIN",
         "Europe",
         "Large",
         "Gates 91-102",
         "2018-12-31",
         "300.0",
         "Average",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "65",
         "387",
         "Friday",
         "ALASKA",
         "INDIANAPOLIS",
         "Midwest US",
         "    Medium",
         "Gates 50-59",
         "2018-12-31",
         "160.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "72",
         "3255",
         "Tuesday",
         "UNITED",
         "SAN DIEGO",
         "West US",
         "Medium",
         "Gates 70-90",
         "2018-12-31",
         "105.0",
         "Average",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "81",
         "1747",
         "Monday",
         "LUFTHANSA",
         "MUNICH",
         "Europe",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "205.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "82",
         "1954",
         "Saturday",
         "AIR FRANCE/KLM",
         "PARIS-DE GAULLE",
         "Europe",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "245.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "85",
         "2334",
         "Tuesday",
         "DELTA",
         "MINNEAPOLIS-ST. PAUL",
         "Midwest US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "155.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "86",
         "1887",
         "Tuesday",
         "UNITED",
         "BOSTON",
         "East US",
         "Large",
         "Gates 70-90",
         "2018-12-31",
         "84.9999999999999",
         "Somewhat clean",
         "Neutral",
         "Neutral"
        ],
        [
         "90",
         "1593",
         "Thursday",
         "SOUTHWEST",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "50.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "91",
         "716",
         "Wednesday",
         "CATHAY PACIFIC",
         "HONG KONG",
         "Asia",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "270.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "93",
         "2038",
         "Friday",
         "BRITISH AIRWAYS",
         "LONDON HEATHROW",
         "eur",
         "    Hub",
         "Gates 1-12",
         "2018-12-31",
         "150.0",
         "Average",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "95",
         "746",
         "Sunday",
         "ALASKA",
         "NEW YORK-JFK",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "120.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "97",
         "1984",
         "Friday",
         "AIR FRANCE/KLM",
         "AMSTERDAM",
         "eur",
         "    Hub",
         "Gates 1-12",
         "2018-12-31",
         "115.0",
         "Average",
         "Neutral",
         "Somewhat unsatisfied"
        ],
        [
         "101",
         "1252",
         "Thursday",
         "UNITED INTL",
         "TOKYO-NARITA",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "120.0",
         "Somewhat clean",
         "Somewhat safe",
         "Very satisfied"
        ],
        [
         "102",
         "1946",
         "Saturday",
         "AIR FRANCE/KLM",
         "PARIS-DE GAULLE",
         "Europe",
         "Hub",
         "Gates 1-12",
         "2018-12-31",
         "305.0",
         "Clean",
         "Very safe",
         "Neutral"
        ],
        [
         "103",
         "2627",
         "Tuesday",
         "UNITED",
         "CHICAGO-O'HARE",
         "Midwest US",
         "Hub",
         "Gates 60-69",
         "2018-12-31",
         "74.9999999999999",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "104",
         "1563",
         "Wednesday",
         "DELTA",
         "ATLANTA",
         "East US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "135.0",
         "Somewhat clean",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "105",
         "752",
         "Thursday",
         "AIR CANADA",
         "TORONTO",
         "Canada/Mexico",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "235.0",
         "Somewhat clean",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "108",
         "2220",
         "Thursday",
         "SOUTHWEST",
         "PHOENIX",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "95.0",
         "Somewhat clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "109",
         "3065",
         "Tuesday",
         "UNITED",
         "SPOKANE",
         "West US",
         "Small",
         "Gates 70-90",
         "2018-12-31",
         "112.0",
         "Average",
         "Neutral",
         "Neutral"
        ],
        [
         "112",
         "884",
         "Tuesday",
         "ALASKA",
         "SEATTLE",
         "West US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "85.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "113",
         "2054",
         "Friday",
         "UNITED",
         "NEWARK",
         "East US",
         "Hub",
         "Gates 70-90",
         "2018-12-31",
         "150.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "114",
         "1571",
         "Wednesday",
         "DELTA",
         "DETROIT",
         "Midwest US",
         "Large",
         "Gates 40-48",
         "2018-12-31",
         "155.0",
         "Somewhat clean",
         "Very safe",
         "Neutral"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 1128
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>634</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NEWARK</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2592</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>AEROMEXICO</td>\n",
       "      <td>MEXICO CITY</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>215.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>2399</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>BEIJING</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>195.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>394</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2222</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>PHOENIX</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>165.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2684</td>\n",
       "      <td>Friday</td>\n",
       "      <td>UNITED</td>\n",
       "      <td>ORLANDO</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 70-90</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>2549</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>JETBLUE</td>\n",
       "      <td>LONG BEACH</td>\n",
       "      <td>West US</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        day      airline        destination    dest_region  \\\n",
       "0     1351    Tuesday  UNITED INTL             KANSAI           Asia   \n",
       "1      373     Friday       ALASKA  SAN JOSE DEL CABO  Canada/Mexico   \n",
       "2     2820   Thursday        DELTA        LOS ANGELES        West US   \n",
       "5      634   Thursday       ALASKA             NEWARK        East US   \n",
       "7     2592   Saturday   AEROMEXICO        MEXICO CITY  Canada/Mexico   \n",
       "...    ...        ...          ...                ...            ...   \n",
       "2467  2399  Wednesday  UNITED INTL            BEIJING           Asia   \n",
       "2470   394     Friday       ALASKA        LOS ANGELES        West US   \n",
       "2473  2222   Thursday    SOUTHWEST            PHOENIX        West US   \n",
       "2474  2684     Friday       UNITED            ORLANDO        East US   \n",
       "2475  2549    Tuesday      JETBLUE         LONG BEACH        West US   \n",
       "\n",
       "     dest_size boarding_area   dept_time  wait_min     cleanliness  \\\n",
       "0          Hub  Gates 91-102  2018-12-31     115.0           Clean   \n",
       "1        Small   Gates 50-59  2018-12-31     135.0           Clean   \n",
       "2          Hub   Gates 40-48  2018-12-31      70.0         Average   \n",
       "5          Hub   Gates 50-59  2018-12-31     140.0  Somewhat clean   \n",
       "7          Hub    Gates 1-12  2018-12-31     215.0  Somewhat clean   \n",
       "...        ...           ...         ...       ...             ...   \n",
       "2467       Hub  Gates 91-102  2018-12-31     195.0           Clean   \n",
       "2470       Hub   Gates 50-59  2018-12-31     115.0           Clean   \n",
       "2473       Hub   Gates 20-39  2018-12-31     165.0           Clean   \n",
       "2474       Hub   Gates 70-90  2018-12-31      92.0           Clean   \n",
       "2475     Small    Gates 1-12  2018-12-31      95.0           Clean   \n",
       "\n",
       "             safety    satisfaction  \n",
       "0           Neutral  Very satisfied  \n",
       "1         Very safe  Very satisfied  \n",
       "2     Somewhat safe         Neutral  \n",
       "5         Very safe  Very satisfied  \n",
       "7         Very safe         Neutral  \n",
       "...             ...             ...  \n",
       "2467        Neutral  Very satisfied  \n",
       "2470      Very safe  Very satisfied  \n",
       "2473      Very safe  Very satisfied  \n",
       "2474      Very safe  Very satisfied  \n",
       "2475  Somewhat safe  Very satisfied  \n",
       "\n",
       "[1128 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Isolate the vast majority of the data that is clean\n",
    "clean_airlines = airlines[~inconsistent_rows]\n",
    "display(clean_airlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6352a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the typo using .loc for safe assignment\n",
    "# The first argument to .loc specifies the rows (our boolean mask)\n",
    "# The second argument specifies the column ('satisfaction')\n",
    "airlines.loc[inconsistent_rows, \"satisfaction\"] = \"Somewhat satisfied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e5f3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each column in the 'categories' DataFrame\n",
    "for col in categories.columns:\n",
    "    # Get the unique values from the airline data for the current column\n",
    "    airline_categories = set(airlines[col].unique())\n",
    "\n",
    "    # Get the standard-defined categories, dropping any potential NaN values\n",
    "    standard_categories = set(categories[col].dropna().unique())\n",
    "\n",
    "    # Find the values present in the airline data but not in the standard\n",
    "    discrepancies = airline_categories.difference(standard_categories)\n",
    "\n",
    "    # If the set of discrepancies is not empty, print a report for that column\n",
    "    if discrepancies:\n",
    "        print(f\"Inconsistent values found in '{col}': {discrepancies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5419ba",
   "metadata": {},
   "source": [
    "## Visualising Categorical Data\n",
    "\n",
    "Visualising data is one of the most critical steps in the exploratory data analysis (EDA) process. When dealing with categorical variables, our goals often revolve around understanding the distribution of data within categories, comparing distributions across different categories, or examining the relationship between a categorical variable and a numerical one. The **seaborn** library, built atop **matplotlib**, provides a high-level, declarative API that is exceptionally well-suited for creating aesthetically pleasing and informative statistical graphics.\n",
    "\n",
    "```python\n",
    "# Generate a sample DataFrame for consistent examples\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'category': np.random.choice(['Alpha', 'Beta', 'Gamma', 'Delta'], 200),\n",
    "    'numeric_value': np.random.randn(200) * 20 + 50,\n",
    "    'group_hue': np.random.choice(['G1', 'G2'], 200)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.loc[df['category'] == 'Gamma', 'numeric_value'] += 15\n",
    "df.loc[df['category'] == 'Delta', 'numeric_value'] -= 10\n",
    "```\n",
    "\n",
    "\n",
    "### Plots for Individual Observations: `stripplot` and `swarmplot`\n",
    "\n",
    "These plots are ideal when you want to see every single data point. They excel at showing the underlying distribution of a numerical variable for each category, which is particularly useful for smaller datasets where a summary might hide important details.\n",
    "\n",
    "#### `stripplot`\n",
    "\n",
    "A **stripplot** renders a scatter plot where one of the variables is categorical. It is one of the most straightforward ways to visualise the relationship between a categorical and a continuous variable.\n",
    "\n",
    "  * **Why & When to Use It**: Use a stripplot to get a quick and direct view of the data distribution. It is most effective when the number of data points per category is small. Its primary function is to show where each observation lies along the numerical axis for its respective category.\n",
    "  * **Best Practices**: The main drawback of a stripplot is that points can overlap, making it difficult to discern the true density of the distribution, especially in crowded regions. To mitigate this, the `jitter` parameter can be used to add a small amount of random noise along the categorical axis, spreading the points out horizontally.\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a figure and axes object\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the stripplot\n",
    "sns.stripplot(x='category', y='numeric_value', data=df, ax=ax, jitter=True)\n",
    "\n",
    "# Set titles and labels for clarity\n",
    "ax.set_title('Stripplot of Numeric Values by Category', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Numeric Value', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The resulting plot shows each observation as a distinct point, giving us a sense of the spread and central tendency for each category.\n",
    "\n",
    "#### `swarmplot`\n",
    "\n",
    "A **swarmplot** is a more sophisticated version of a stripplot that aims to solve the point-overlap problem. It positions the points along the categorical axis using an algorithm that prevents them from overlapping, effectively creating a plot that doubles as a density representation.\n",
    "\n",
    "  * **Why & When to Use It**: A swarmplot is superior to a stripplot when you want to see the distribution shape in addition to the individual data points. It provides a clearer picture of the data density and is excellent for highlighting unimodal, bimodal, or other distributional patterns.\n",
    "  * **Best Practices**: The key strength of the swarmplot is its clarity. However, its main limitation is scalability. The algorithm to position the points is computationally intensive and does not scale well to very large datasets. With too many points, the \"swarms\" can become compressed and difficult to read. It is best used for small to medium-sized datasets.\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a new figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the swarmplot\n",
    "sns.swarmplot(x='category', y='numeric_value', data=df, ax=ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Swarmplot of Numeric Values by Category', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Numeric Value', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Notice how this plot reveals the density of points more clearly than the stripplot, providing a more intuitive sense of the distribution for each category.\n",
    "\n",
    "\n",
    "### Abstracted Summaries of Distributions: `boxplot`, `violinplot`, and `boxenplot`\n",
    "\n",
    "When datasets become larger, plotting every single observation is often impractical. Instead, we turn to plots that provide an abstract summary of the distribution. These plots are powerful for comparing distributions across many categories simultaneously.\n",
    "\n",
    "#### `boxplot`\n",
    "\n",
    "The **boxplot** (or box-and-whisker plot) is a classic statistical graphic that provides a standardised five-number summary of a distribution: the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum.\n",
    "\n",
    "  * **Why & When to Use It**: Use a boxplot for a concise summary of a distribution's central tendency and spread. It is exceptionally effective for comparing multiple categories side-by-side and for identifying potential outliers (points that fall outside the whiskers).\n",
    "  * **How to Read It**: The \"box\" represents the interquartile range (IQR), spanning from Q1 to Q3. The line inside the box is the median. The \"whiskers\" typically extend to 1.5 times the IQR from the box edges, and any points beyond the whiskers are flagged as outliers.\n",
    "  * **Best Practices**: The great strength of a boxplot is its simplicity and data density. However, its major weakness is that it completely hides the underlying shape of the distribution. A bimodal (two-peaked) distribution and a unimodal (one-peaked) distribution can have the exact same boxplot.\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the boxplot, using a hue for another layer of grouping\n",
    "sns.boxplot(x='category', y='numeric_value', hue='group_hue', data=df, ax=ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Boxplot of Numeric Values by Category and Group', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Numeric Value', fontsize=12)\n",
    "ax.legend(title='Group')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### `violinplot`\n",
    "\n",
    "A **violinplot** addresses the primary limitation of the boxplot by combining a boxplot with a kernel density estimate (KDE). This hybrid approach provides a much richer understanding of the data.\n",
    "\n",
    "  * **Why & When to Use It**: A violinplot is the preferred choice when the shape of the distribution is important. It shows the same summary statistics as a boxplot but also visualises the probability density of the data at different values. This can easily reveal if a distribution is bimodal, skewed, or uniform.\n",
    "  * **How to Read It**: The width of the violin at a particular y-value indicates the density of data points around that value. Inside the violin, a miniature boxplot or other summary (`inner` parameter) can be displayed.\n",
    "  * **Best Practices**: Violinplots are incredibly informative. However, they can be less intuitive to a non-technical audience than a simple boxplot. The KDE calculation also involves a bandwidth parameter that can influence the final shape, though seaborn's defaults are generally sensible.\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the violinplot\n",
    "sns.violinplot(x='category', y='numeric_value', hue='group_hue', data=df, ax=ax, split=True)\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Violinplot of Numeric Values by Category and Group', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Numeric Value', fontsize=12)\n",
    "ax.legend(title='Group')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The `split=True` argument allows for a more direct comparison between the two `hue` levels.\n",
    "\n",
    "#### `boxenplot`\n",
    "\n",
    "The **boxenplot**, also known as a letter-value plot, was designed as an enhancement to the standard boxplot for larger datasets. It provides a more detailed view of the distribution's tails.\n",
    "\n",
    "  * **Why & When to Use It**: Use a boxenplot when working with larger datasets (`N > 1000`) where a standard boxplot might obscure details about the distribution's shape, particularly in the tails. It plots more quantiles than a boxplot, giving a more nuanced view.\n",
    "  * **How to Read It**: Each successive box (moving outwards from the median) represents a smaller and smaller proportion of the data. This provides more robust estimates of the tail behaviour.\n",
    "  * **Best Practices & Pitfalls**: While powerful, the boxenplot is less common and may require explanation for your audience. For small datasets, it offers little advantage over a violinplot or boxplot.\n",
    "\n",
    "```python\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the boxenplot\n",
    "sns.boxenplot(x='category', y='numeric_value', hue='group_hue', data=df, ax=ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Boxenplot of Numeric Values by Category and Group', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Numeric Value', fontsize=12)\n",
    "ax.legend(title='Group')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Plots for Central Tendency and Counts\n",
    "\n",
    "This final group of plots moves away from showing full distributions and instead focuses on summarising categories with a single value, typically an estimate of central tendency (like the mean) or a simple count.\n",
    "\n",
    "#### `barplot`\n",
    "\n",
    "A **barplot** displays an estimate of central tendency for a numerical variable for each category. By default, it calculates the mean, but this can be changed.\n",
    "\n",
    "  * **Why & When to Use It**: Use a barplot when the primary goal is to compare a summary statistic (e.g., mean, median) across different categories. The black lines on top of the bars represent confidence intervals (bootstrapped by default), giving a sense of the uncertainty in the estimate.\n",
    "  * **Best Practices & Pitfalls**: A barplot is simple and widely understood. However, it provides very little information about the underlying data distribution. A single mean value can be misleading if the data is highly skewed or bimodal. Always be cautious when interpreting a barplot without understanding the distribution.\n",
    "\n",
    "```python\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the barplot\n",
    "sns.barplot(x='category', y='numeric_value', hue='group_hue', data=df, ax=ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Barplot Showing Mean Numeric Value by Category and Group', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Mean Numeric Value', fontsize=12)\n",
    "ax.legend(title='Group')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### `pointplot`\n",
    "\n",
    "A **pointplot** also displays an estimate of central tendency and confidence intervals but uses points and connecting lines instead of bars. This subtle change in representation makes it better for a different analytical purpose.\n",
    "\n",
    "  * **Why & When to Use It**: A pointplot excels at showing *interactions* and *comparisons* across categories, especially when a `hue` variable is used. By connecting the points, it draws the eye to how a relationship changes across the x-axis. It is often less cluttered than a barplot when you have multiple hue levels.\n",
    "  * **Best Practices & Pitfalls**: While excellent for comparing trends, it gives less visual weight to the absolute values compared to a barplot. The connecting line does not imply continuity, which can be a point of confusion for some audiences; it is purely there to guide the eye.\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the pointplot\n",
    "sns.pointplot(x='category', y='numeric_value', hue='group_hue', data=df, ax=ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Pointplot Showing Mean Numeric Value by Category and Group', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Mean Numeric Value', fontsize=12)\n",
    "ax.legend(title='Group')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### `countplot`\n",
    "\n",
    "A **countplot** is the simplest of these plots. It is functionally a histogram across a categorical variable, showing the number of observations in each category.\n",
    "\n",
    "  * **Why & When to Use It**: Use a countplot when your goal is simply to see the frequency of each category in your dataset. Unlike a barplot, you only provide an `x` *or* a `y` variable, not both.\n",
    "  * **Best Practices & Pitfalls**: It is a straightforward and effective plot. The most common pitfall is confusing it with a barplot. Remember: a **countplot** shows counts of a single variable; a **barplot** shows the relationship between a categorical and a numerical variable.\n",
    "\n",
    "\n",
    "```python\n",
    "# Create a figure and axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate the countplot\n",
    "sns.countplot(x='category', hue='group_hue', data=df, ax=ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Count of Observations by Category and Group', fontsize=16)\n",
    "ax.set_xlabel('Category', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.legend(title='Group')\n",
    "\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3763ccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n"
     ]
    }
   ],
   "source": [
    "# Print the unique values in dest_region and dest_size respectively.\n",
    "print(airlines[\"dest_region\"].unique())\n",
    "print(airlines[\"dest_size\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47b9667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# Strip whitespace from dest_size values to clean inconsistent formatting\n",
    "airlines[\"dest_size\"] = airlines[\"dest_size\"].str.strip()\n",
    "\n",
    "# Print the unique values to verify the cleaning worked\n",
    "print(airlines[\"dest_size\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52d169c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n"
     ]
    }
   ],
   "source": [
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines[\"dest_region\"] = airlines[\"dest_region\"].str.lower()\n",
    "airlines[\"dest_region\"] = airlines[\"dest_region\"].replace({\"eur\": \"europe\"})\n",
    "print(airlines[\"dest_region\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022acaa0",
   "metadata": {},
   "source": [
    "### Remapping categories\n",
    "The `airlines` DataFrame contains the `day` and `wait_min` columns, which are categorical and numerical respectively. The `day` column contains the exact day a flight took place, and `wait_min` contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "\n",
    "`wait_type`: `'short'` for 0-60 min, `'medium'` for 60-180 and long for 180+; <br>\n",
    "`day_week`: `'weekday'` if day is in the weekday, `'weekend'` if day is in the weekend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c95ff11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ranges and labels for the wait_type column mentioned in the description.\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = [\"short\", \"medium\", \"long\"]\n",
    "\n",
    "# Create the wait_type column by from wait_min by using pd.cut(), while inputting label_ranges and label_names in the correct arguments.\n",
    "airlines[\"wait_type\"] = pd.cut(airlines[\"wait_min\"], bins=label_ranges, labels=label_names)\n",
    "\n",
    "# Create the mapping dictionary mapping weekdays to 'weekday' and weekend days to 'weekend'.\n",
    "mappings = {\n",
    "    \"Monday\": \"weekday\",\n",
    "    \"Tuesday\": \"weekday\",\n",
    "    \"Wednesday\": \"weekday\",\n",
    "    \"Thursday\": \"weekday\",\n",
    "    \"Friday\": \"weekday\",\n",
    "    \"Saturday\": \"weekend\",\n",
    "    \"Sunday\": \"weekend\",\n",
    "}\n",
    "\n",
    "# Create the day_week column by using .replace().\n",
    "airlines[\"day_week\"] = airlines[\"day\"].replace(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "776ba6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medium', 'long', 'short']\n",
      "Categories (3, object): ['short' < 'medium' < 'long']\n",
      "['weekday' 'weekend']\n"
     ]
    }
   ],
   "source": [
    "print(airlines[\"wait_type\"].unique())\n",
    "print(airlines[\"day_week\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02b657cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2477 entries, 0 to 2476\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   id             2477 non-null   int64   \n",
      " 1   day            2477 non-null   object  \n",
      " 2   airline        2477 non-null   object  \n",
      " 3   destination    2477 non-null   object  \n",
      " 4   dest_region    2477 non-null   object  \n",
      " 5   dest_size      2477 non-null   object  \n",
      " 6   boarding_area  2477 non-null   object  \n",
      " 7   dept_time      2477 non-null   object  \n",
      " 8   wait_min       2477 non-null   float64 \n",
      " 9   cleanliness    2477 non-null   object  \n",
      " 10  safety         2477 non-null   object  \n",
      " 11  satisfaction   2477 non-null   object  \n",
      " 12  wait_type      2477 non-null   category\n",
      " 13  day_week       2477 non-null   object  \n",
      "dtypes: category(1), float64(1), int64(1), object(11)\n",
      "memory usage: 254.2+ KB\n"
     ]
    }
   ],
   "source": [
    "airlines.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28fd32b",
   "metadata": {},
   "source": [
    "## Cleaning Text Data\n",
    "\n",
    "Text data, in the context of data analysis, refers to any information stored in a string format. This can range from highly structured identifiers like serial numbers or email addresses to completely unstructured free-form text like product reviews or social media comments. While incredibly rich with information, raw text data is notoriously \"dirty\" and requires rigorous cleaning before it can be used for any meaningful analysis or modelling. Failure to properly clean text data can lead to inaccurate results, biased models, and flawed conclusions.\n",
    "\n",
    "\n",
    "```python\n",
    "# A sample DataFrame demonstrating various text data problems\n",
    "# We use a generic 'identifier' column to focus on principles\n",
    "data = {\n",
    "    'record_id': range(6),\n",
    "    'identifier': [\n",
    "        'ID: 945-332-110', # Contains punctuation and spaces\n",
    "        '+1 (408) 999 3421', # Inconsistent international format\n",
    "        'SKU_4431_B', # Contains letters and underscores\n",
    "        '721', # Violates minimum length assumption\n",
    "        '  id: 945 332 110  ', # Leading/trailing whitespace and case inconsistency\n",
    "        'SKU-4431-C' # Different separator\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "### Common Problems in Text Data\n",
    "\n",
    "Text data issues can generally be categorised into three main areas: inconsistencies in format, violations of structural rules, and the presence of unwanted characters or typos.\n",
    "\n",
    "1.  **Data Inconsistency**: This is when the same conceptual value is represented in multiple ways. For example, a country code might appear as `+1`, `001`, or not at all. This prevents accurate grouping and analysis.\n",
    "\n",
    "2.  **Fixed-Length and Structural Violations**: Many types of identifiers have explicit rules, such as a credit card number having 16 digits or a password requiring a minimum length. Data that violates these rules is often invalid.\n",
    "\n",
    "3.  **Typos and Extraneous Characters**: This broad category includes simple misspellings, unwanted punctuation, non-printable characters, or inconsistent capitalisation and whitespace.\n",
    "\n",
    "Let's observe these problems in our initial DataFrame:\n",
    "\n",
    "```python\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### Expected Output\n",
    "\n",
    "| record_id | identifier          |\n",
    "|-----------|---------------------|\n",
    "| 0         | ID: 945-332-110     |\n",
    "| 1         | +1 (408) 999 3421   |\n",
    "| 2         | SKU_4431_B          |\n",
    "| 3         | 721                 |\n",
    "| 4         | id: 945 332 110     |\n",
    "| 5         | SKU-4431-C          |\n",
    "\n",
    "\n",
    "Our goal is to standardise this `identifier` column into a consistent, digits-only format, flagging any records that do not meet a minimum length requirement after cleaning.\n",
    "\n",
    "### A Systematic Approach to Cleaning\n",
    "\n",
    "A robust cleaning process involves a series of sequential, atomic operations. We will use the powerful `.str` accessor in `pandas`, which allows us to apply string methods to an entire Series in a vectorized, efficient manner.\n",
    "\n",
    "#### Step 1: Standardise Case and Whitespace\n",
    "\n",
    "A foundational first step is to eliminate superficial inconsistencies from capitalisation and extraneous whitespace. This ensures that `'  text  '` and `'TEXT'` are treated identically.\n",
    "\n",
    "* **Why**: This is a low-effort, high-impact normalisation step. It prevents simple formatting differences from being interpreted as distinct values.\n",
    "* **How**: We chain the `.str.lower()` and `.str.strip()` methods for a concise and efficient operation.\n",
    "\n",
    "```python\n",
    "# Create a new column for the cleaned data to preserve the original\n",
    "df['identifier_cleaned'] = df['identifier'].str.lower().str.strip()\n",
    "\n",
    "print(df[['identifier', 'identifier_cleaned']])\n",
    "```\n",
    "\n",
    "#### Step 2: Removing All Non-Digit Characters with Regular Expressions\n",
    "\n",
    "Our goal is to create a purely numeric identifier. Simple methods like `.str.replace('-', '')` are brittle because we would need a separate call for every possible non-digit character (`+`, `(`, `)`, `_`, etc.). A far more powerful and scalable solution is to use a **regular expression**.\n",
    "\n",
    "A regular expression (or regex) is a special sequence of characters that defines a search pattern. We will use the pattern `\\D+`.\n",
    "\n",
    "  * `\\D`: This is a special regex character class that matches any character that is **not** a digit (0-9).\n",
    "  * `+`: This is a quantifier that means \"one or more\" of the preceding character.\n",
    "\n",
    "So, `\\D+` matches one or more consecutive non-digit characters.\n",
    "\n",
    "  * **Why**: Regular expressions provide a concise and powerful syntax for finding and replacing complex patterns, making them indispensable for text cleaning. A single regex can replace dozens of simple `.replace()` calls.\n",
    "  * **How**: We use `.str.replace()` but pass our regex pattern. The `r` prefix before the string `r'\\D+'` signifies a \"raw string,\" which is a best practice for writing regex patterns in Python to avoid issues with backslashes.\n",
    "\n",
    "```python\n",
    "# Replace any sequence of one or more non-digit characters with an empty string\n",
    "df['identifier_cleaned'] = df['identifier_cleaned'].str.replace(r'\\D+', '', regex=True)\n",
    "\n",
    "print(df[['identifier', 'identifier_cleaned']])\n",
    "```\n",
    "\n",
    "#### Expected Output\n",
    "\n",
    "| record_id | identifier          | identifier_cleaned |\n",
    "|-----------|---------------------|-------------------|\n",
    "| 0         | ID: 945-332-110     | 945332110         |\n",
    "| 1         | +1 (408) 999 3421   | 14089993421       |\n",
    "| 2         | SKU_4431_B          | 4431              |\n",
    "| 3         | 721                 | 721               |\n",
    "| 4         | id: 945 332 110     | 945332110         |\n",
    "| 5         | SKU-4431-C          | 4431              |\n",
    "\n",
    "\n",
    "As you can see, Jhonatan, this single line of code has effectively stripped all non-numeric characters from every entry, demonstrating the power of this approach.\n",
    "\n",
    "#### Step 3: Enforcing Structural Rules (e.g., Minimum Length)\n",
    "\n",
    "Now that our identifiers are in a consistent format, we can validate them against structural rules. Let's assume a valid identifier must have at least 10 digits. Records that do not meet this criterion should be marked as invalid (e.g., set to `NaN` - Not a Number).\n",
    "\n",
    "* **Why**: Enforcing structural integrity ensures that the data is valid for its intended purpose. Invalid data should be explicitly handled (e.g., removed or flagged for review) rather than allowed to corrupt analyses.\n",
    "* **How**: We first calculate the length of each cleaned string using `.str.len()`. Then, we use boolean indexing with `.loc` to select the rows where the length is less than our threshold and set their values to `np.nan`.\n",
    "\n",
    "```python\n",
    "# Calculate the length of each string in the cleaned column\n",
    "identifier_lengths = df['identifier_cleaned'].str.len()\n",
    "\n",
    "# Use .loc to find rows where the length is less than 10 and set them to NaN\n",
    "# This is the correct, idiomatic way to perform conditional assignment in pandas\n",
    "df.loc[identifier_lengths < 10, 'identifier_cleaned'] = np.nan\n",
    "\n",
    "print(df[['identifier', 'identifier_cleaned']])\n",
    "```\n",
    "\n",
    "#### Expected Output\n",
    "| record_id | identifier          | identifier_cleaned |\n",
    "|-----------|---------------------|-------------------|\n",
    "| 0         | ID: 945-332-110     | 945332110         |\n",
    "| 1         | +1 (408) 999 3421   | 14089993421       |\n",
    "| 2         | SKU_4431_B          | NaN               |\n",
    "| 3         | 721                 | NaN               |\n",
    "| 4         | id: 945 332 110     | 945332110         |\n",
    "| 5         | SKU-4431-C          | NaN               |\n",
    "\n",
    "#### Step 4: Sanity Checking with Assertions\n",
    "\n",
    "After cleaning, it is a crucial best practice to programmatically verify that your data meets the expected conditions. The `assert` statement is perfect for this. It checks if a condition is true, and if not, it raises an `AssertionError`, immediately halting the program. This is a powerful way to catch data quality issues early.\n",
    "\n",
    "* **Why**: Assertions act as a safety net. They codify your assumptions about the data's state after cleaning. If an assertion fails, it means your cleaning logic was flawed or the incoming data had an unexpected format, and it prevents the corrupted data from being used downstream.\n",
    "* **How**: We write `assert` statements that check our conditions. An assertion that passes produces no output.\n",
    "\n",
    "```python\n",
    "# Drop rows with NaN to check the remaining valid data\n",
    "final_data = df.dropna(subset=['identifier_cleaned'])\n",
    "\n",
    "# 1. Assert that the minimum length of valid identifiers is at least 10\n",
    "assert final_data['identifier_cleaned'].str.len().min() >= 10\n",
    "\n",
    "# 2. Assert that all valid identifiers are composed only of digits\n",
    "assert final_data['identifier_cleaned'].str.isdigit().all()\n",
    "\n",
    "# 3. Assert that there is no whitespace left\n",
    "assert final_data['identifier_cleaned'].str.contains(' ').any() == False\n",
    "\n",
    "print(\"All assertions passed. Data is clean and validated.\")\n",
    "```\n",
    "\n",
    "Since no errors were raised, we can be confident that our cleaning process was successful and the resulting data adheres to our defined quality standards.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af27d9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "full_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "airline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "destination",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "boarding_area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dept_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wait_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cleanliness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "satisfaction",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d559c82d-b5f5-426f-8333-a5ae78c1f1ee",
       "rows": [
        [
         "0",
         "1351",
         "Melodie Stuart",
         "Tuesday",
         "UNITED INTL",
         "KANSAI",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "115.0",
         "Clean",
         "Neutral",
         "Very satisfied"
        ],
        [
         "1",
         "373",
         "Dominic Shannon",
         "Friday",
         "ALASKA",
         "SAN JOSE DEL CABO",
         "Canada/Mexico",
         "Small",
         "Gates 50-59",
         "2018-12-31",
         "135.0",
         "Clean",
         "Very safe",
         "Very satisfied"
        ],
        [
         "2",
         "2820",
         "Quintessa Tillman",
         "Thursday",
         "DELTA",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "70.0000000000001",
         "Average",
         "Somewhat safe",
         "Neutral"
        ],
        [
         "3",
         "1157",
         "Dr. Christine Nicholson",
         "Tuesday",
         "SOUTHWEST",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "190.0",
         "Clean",
         "Very safe",
         "Somewhat satsified"
        ],
        [
         "4",
         "2992",
         "Regina Clements",
         "Wednesday",
         "AMERICAN",
         "MIAMI",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "559.0",
         "Somewhat clean",
         "Very safe",
         "Somewhat satsified"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Melodie Stuart</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Dominic Shannon</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Quintessa Tillman</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157</td>\n",
       "      <td>Dr. Christine Nicholson</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2992</td>\n",
       "      <td>Regina Clements</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satsified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                full_name        day      airline        destination  \\\n",
       "0  1351           Melodie Stuart    Tuesday  UNITED INTL             KANSAI   \n",
       "1   373          Dominic Shannon     Friday       ALASKA  SAN JOSE DEL CABO   \n",
       "2  2820        Quintessa Tillman   Thursday        DELTA        LOS ANGELES   \n",
       "3  1157  Dr. Christine Nicholson    Tuesday    SOUTHWEST        LOS ANGELES   \n",
       "4  2992          Regina Clements  Wednesday     AMERICAN              MIAMI   \n",
       "\n",
       "     dest_region dest_size boarding_area   dept_time  wait_min  \\\n",
       "0           Asia       Hub  Gates 91-102  2018-12-31     115.0   \n",
       "1  Canada/Mexico     Small   Gates 50-59  2018-12-31     135.0   \n",
       "2        West US       Hub   Gates 40-48  2018-12-31      70.0   \n",
       "3        West US       Hub   Gates 20-39  2018-12-31     190.0   \n",
       "4        East US       Hub   Gates 50-59  2018-12-31     559.0   \n",
       "\n",
       "      cleanliness         safety        satisfaction  \n",
       "0           Clean        Neutral      Very satisfied  \n",
       "1           Clean      Very safe      Very satisfied  \n",
       "2         Average  Somewhat safe             Neutral  \n",
       "3           Clean      Very safe  Somewhat satsified  \n",
       "4  Somewhat clean      Very safe  Somewhat satsified  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_fn = pd.read_csv(\"https://raw.githubusercontent.com/jhlopesalves/data-science-practice-notebook/refs/heads/main/Python/data_manipulation/pandas/cleaning_data/data/airline_fn.csv\", usecols=lambda col: not col.startswith(\"Unnamed\"))\n",
    "airlines_fn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47694cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"Dr.\", \"Mr.\", \"Miss\" and \"Ms.\" from full_name by replacing them with an empty string \"\" in that order.\n",
    "titles = [\"Dr.\", \"Mr.\", \"Miss\", \"Ms.\"]\n",
    "\n",
    "for title in titles:\n",
    "    airlines_fn[\"full_name\"] = airlines_fn[\"full_name\"].str.replace(title, \"\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4789ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that full_name has no honorifics\n",
    "assert airlines_fn[\"full_name\"].str.contains(\"Ms.|Mr.|Miss|Dr.\").any() == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f960b243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "day",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "airline",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "destination",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_region",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dest_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "boarding_area",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dept_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "wait_min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cleanliness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "safety",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "satisfaction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "survey_response",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "71bdfd54-b48f-4b8c-a0f7-13b56d95499d",
       "rows": [
        [
         "0",
         "1351",
         "Tuesday",
         "UNITED INTL",
         "KANSAI",
         "Asia",
         "Hub",
         "Gates 91-102",
         "2018-12-31",
         "115.0",
         "Dirty",
         "Very unsafe",
         "Very unsatisfied",
         "It was terrible"
        ],
        [
         "1",
         "373",
         "Friday",
         "ALASKA",
         "SAN JOSE DEL CABO",
         "Canada/Mexico",
         "Small",
         "Gates 50-59",
         "2018-12-31",
         "135.0",
         "Dirty",
         "Very unsafe",
         "Very unsatisfied",
         "I didn't like the flight"
        ],
        [
         "2",
         "2820",
         "Thursday",
         "DELTA",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 40-48",
         "2018-12-31",
         "70.0000000000001",
         "Dirty",
         "Very unsafe",
         "Very unsatisfied",
         "I hate this "
        ],
        [
         "3",
         "1157",
         "Tuesday",
         "SOUTHWEST",
         "LOS ANGELES",
         "West US",
         "Hub",
         "Gates 20-39",
         "2018-12-31",
         "190.0",
         "Dirty",
         "Very unsafe",
         "Very unsatisfied",
         "Not a fan"
        ],
        [
         "4",
         "2992",
         "Wednesday",
         "AMERICAN",
         "MIAMI",
         "East US",
         "Hub",
         "Gates 50-59",
         "2018-12-31",
         "559.0",
         "Dirty",
         "Very unsafe",
         "Very unsatisfied",
         "Bad"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>survey_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "      <td>It was terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "      <td>I didn't like the flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "      <td>I hate this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "      <td>Not a fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Dirty</td>\n",
       "      <td>Very unsafe</td>\n",
       "      <td>Very unsatisfied</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id        day      airline        destination    dest_region dest_size  \\\n",
       "0  1351    Tuesday  UNITED INTL             KANSAI           Asia       Hub   \n",
       "1   373     Friday       ALASKA  SAN JOSE DEL CABO  Canada/Mexico     Small   \n",
       "2  2820   Thursday        DELTA        LOS ANGELES        West US       Hub   \n",
       "3  1157    Tuesday    SOUTHWEST        LOS ANGELES        West US       Hub   \n",
       "4  2992  Wednesday     AMERICAN              MIAMI        East US       Hub   \n",
       "\n",
       "  boarding_area   dept_time  wait_min cleanliness       safety  \\\n",
       "0  Gates 91-102  2018-12-31     115.0       Dirty  Very unsafe   \n",
       "1   Gates 50-59  2018-12-31     135.0       Dirty  Very unsafe   \n",
       "2   Gates 40-48  2018-12-31      70.0       Dirty  Very unsafe   \n",
       "3   Gates 20-39  2018-12-31     190.0       Dirty  Very unsafe   \n",
       "4   Gates 50-59  2018-12-31     559.0       Dirty  Very unsafe   \n",
       "\n",
       "       satisfaction           survey_response  \n",
       "0  Very unsatisfied           It was terrible  \n",
       "1  Very unsatisfied  I didn't like the flight  \n",
       "2  Very unsatisfied              I hate this   \n",
       "3  Very unsatisfied                 Not a fan  \n",
       "4  Very unsatisfied                       Bad  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_sr = pd.read_csv(\"https://raw.githubusercontent.com/jhlopesalves/data-science-practice-notebook/refs/heads/main/Python/data_manipulation/pandas/cleaning_data/data/airline_survey.csv\", usecols=lambda col: not col.startswith(\"Unnamed\"))\n",
    "airline_sr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74676f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17    The airport personnell forgot to alert us of d...\n",
      "18    The food in the airport was really really expe...\n",
      "19    One of the other travelers was really loud and...\n",
      "20    I don't remember answering the survey with the...\n",
      "21    The airport personnel kept ignoring my request...\n",
      "22    The chair I sat in was extremely uncomfortable...\n",
      "23    I wish you were more like other airports, the ...\n",
      "24    I was really unsatisfied with the wait times b...\n",
      "25    The flight was okay, but I didn't really like ...\n",
      "26    We were really slowed down by security measure...\n",
      "27    There was a spill on the aisle next to the bat...\n",
      "28    I felt very unsatisfied by how long the flight...\n",
      "Name: survey_response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Using the airlines DataFrame, store the length of each instance in the survey_response column in resp_length by using .str.len().\n",
    "resp_length = airline_sr[\"survey_response\"].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airline_sr[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey[\"survey_response\"].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey[\"survey_response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879992d",
   "metadata": {},
   "source": [
    "## Ensuring Data Uniformity\n",
    "\n",
    "```python\n",
    "# Sample DataFrame demonstrating non-uniform numerical data\n",
    "df_temps = pd.DataFrame({\n",
    "    'day': pd.to_datetime(['2023-07-01', '2023-07-02', '2023-07-03', '2023-07-04', '2023-07-05']),\n",
    "    'measurement': [25.0, 26.5, 24.0, 80.6, 27.0] # A mix of Celsius and Fahrenheit\n",
    "})\n",
    "\n",
    "# Sample DataFrame demonstrating non-uniform date formats\n",
    "df_events = pd.DataFrame({\n",
    "    'event_date': ['01/10/2023', 'Oct 2, 2023', '2023-10-03', '04-10-23', 'Invalid Date'],\n",
    "    'event_name': ['A', 'B', 'C', 'D', 'E']\n",
    "})\n",
    "```\n",
    "\n",
    "### Data Range Constraints and Inconsistent Units\n",
    "\n",
    "One of the most common uniformity problems arises when a numerical column contains data from different measurement systems. This violates the fundamental assumption that all values in the column are directly comparable.\n",
    "\n",
    "#### The Problem: Hidden Outliers\n",
    "\n",
    "Consider our `df_temps` DataFrame. A quick glance at the `measurement` column reveals a value, `80.6`, that seems drastically out of place compared to the others. This is a classic symptom of a unit inconsistency. While it appears to be a statistical outlier, it is, in fact, an *artefact* of being recorded in a different unit (Fahrenheit) while the others are in Celsius.\n",
    "\n",
    "#### Visual Diagnosis\n",
    "\n",
    "A simple plot can often make these issues immediately obvious. A value that is semantically different but numerically large will appear as a stark outlier, prompting investigation.\n",
    "\n",
    "  * **Why**: Visualisation is a powerful diagnostic tool. The human eye is excellent at spotting patterns and deviations. A scatter plot or line plot can instantly highlight points that break the established trend, which are often the result of data quality issues.\n",
    "  * **How**: We use `matplotlib` to create a simple plot. The inconsistent point will dramatically skew the y-axis and visually detach from the other data points.\n",
    "\n",
    "```python\n",
    "# Create a figure and axes object\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Generate a line plot to show the trend\n",
    "ax.plot(df_temps['day'], df_temps['measurement'], marker='o')\n",
    "ax.scatter(df_temps['day'], df_temps['measurement'], color='red') # Emphasize points\n",
    "\n",
    "# Set titles and labels\n",
    "ax.set_title('Recorded Measurements Over Time', fontsize=16)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Measurement Value', fontsize=12)\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "The plot clearly isolates the `80.6` value, confirming our suspicion that it does not belong to the same distribution as the other points.\n",
    "\n",
    "#### The Solution: Isolate, Convert, and Validate\n",
    "\n",
    "The strategy to fix this involves three pythonic steps:\n",
    "\n",
    "1.  **Isolate**: Use boolean indexing with `.loc` to select the data that needs conversion. We define a plausible range for our target unit (Celsius) and select any data that falls outside of it.\n",
    "2.  **Convert**: Apply the appropriate mathematical formula to the isolated data to convert it to the target unit. For Fahrenheit to Celsius, the formula is `C = (F - 32) * 5/9`.\n",
    "3.  **Validate**: After conversion, use an `assert` statement to programmatically confirm that all data now conforms to the expected range.\n",
    "\n",
    "```python\n",
    "# 1. Isolate the Fahrenheit values. We assume any measurement over a plausible\n",
    "# Celsius threshold (e.g., 40) is in Fahrenheit.\n",
    "is_fahrenheit = df_temps['measurement'] > 40\n",
    "fahrenheit_values = df_temps.loc[is_fahrenheit, 'measurement']\n",
    "\n",
    "# 2. Convert these values to Celsius.\n",
    "celsius_values = (fahrenheit_values - 32) * 5/9\n",
    "\n",
    "# 3. Assign the converted values back into the DataFrame using .loc\n",
    "df_temps.loc[is_fahrenheit, 'measurement'] = celsius_values\n",
    "\n",
    "# 4. Validate the result with an assertion.\n",
    "# This will raise an AssertionError if the condition is false.\n",
    "# A passing assertion produces no output.\n",
    "assert df_temps['measurement'].max() < 40\n",
    "\n",
    "print(\"--- Cleaned Temperature Data ---\")\n",
    "print(df_temps)\n",
    "```\n",
    "\n",
    "This methodical approach ensures that the data is not only corrected but also verified, providing confidence in its uniformity.\n",
    "\n",
    "### Standardising Date and Time Formats\n",
    "\n",
    "Dates are another frequent source of uniformity issues because they can be represented in countless formats (`DD-MM-YYYY`, `MM/DD/YY`, `Month Day, Year`, etc.). For a computer to interpret dates correctly for time-series analysis or duration calculations, they must be converted to a standardised `datetime` object.\n",
    "\n",
    "#### The Challenge: Ambiguity and Errors\n",
    "\n",
    "Look at our `df_events` DataFrame. It contains multiple date formats and even an invalid entry. A naive attempt to convert this column will likely fail. Furthermore, formats like `04-10-23` are ambiguous: is this April 10th or October 4th?\n",
    "\n",
    "#### The Pythonic Solution: `pd.to_datetime()`\n",
    "\n",
    "The canonical tool for this job in `pandas` is the `pd.to_datetime()` function. It is powerful and flexible, but its true strength lies in its error-handling capabilities.\n",
    "\n",
    "  * **Why**: `pd.to_datetime()` is engineered to parse a wide variety of string formats. Its parameters allow you to handle the inevitable errors and ambiguities of real-world date data gracefully, without your entire script failing due to a single malformed entry.\n",
    "  * **How**: The key is to use the `errors` parameter. Setting `errors='coerce'` is a crucial best practice. Instead of raising a `ValueError` when it encounters a string it cannot parse (like `'Invalid Date'`), it will replace that entry with `NaT` (Not a Time), the datetime equivalent of `NaN`. This allows you to identify and handle problematic rows separately.\n",
    "\n",
    "\n",
    "```python\n",
    "# Convert the 'event_date' column to datetime objects\n",
    "# 'errors='coerce'' is essential for robust parsing\n",
    "df_events['event_date_parsed'] = pd.to_datetime(df_events['event_date'], errors='coerce')\n",
    "\n",
    "print(\"--- Parsed Date Data ---\")\n",
    "print(df_events)\n",
    "```\n",
    "\n",
    "The `event_date_parsed` column now holds proper `datetime` objects, with the unparseable string correctly marked as `NaT`.\n",
    "\n",
    "#### Reformatting for Uniform Presentation\n",
    "\n",
    "Once the data is in a `datetime` format, you have full programmatic control. You can easily convert it back to a string in any single, uniform format you choose using the `.dt.strftime()` accessor. This is perfect for creating clean, consistent reports or visualisations.\n",
    "\n",
    "`strftime` uses special codes (`%Y` for 4-digit year, `%m` for month, `%d` for day) to define the output format.\n",
    "\n",
    "```python\n",
    "# Create a new column with the date formatted uniformly as YYYY-MM-DD\n",
    "df_events['event_date_uniform'] = df_events['event_date_parsed'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"\\n--- Uniformly Formatted Date Strings ---\")\n",
    "print(df_events[['event_date', 'event_date_uniform']])\n",
    "```\n",
    "\n",
    "#### A Note on Ambiguous Dates\n",
    "\n",
    "How does `pandas` handle `04-10-23`? By default, in many environments, it assumes a month-first format (`MM-DD-YY`). If your data is day-first, you can provide a hint with the `dayfirst=True` argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0dcca",
   "metadata": {},
   "source": [
    "### Uniform currencies\n",
    "\n",
    "The dataset contains data on the amount of money stored in accounts (`acct_amount`), their currency (`acct_cur`), amount invested (`inv_amount`), account opening date (`account_opened`), and last transaction date (`last_transaction`) that were consolidated from American and European branches.\n",
    "\n",
    "You are tasked with understanding the average account size and how investments vary by the size of account, however in order to produce this analysis accurately, you first need to unify the currency amount into dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02cf5287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cust_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "acct_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "acct_cur",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "inv_amount",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "account_opened",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "last_transaction",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2111fbf3-a535-4cfe-926b-55ab922bbe3b",
       "rows": [
        [
         "0",
         "8C35540A",
         "44244.71",
         "dollar",
         "35500.5",
         "03-05-18",
         "30-09-19"
        ],
        [
         "1",
         "D5536652",
         "86506.85",
         "dollar",
         "81921.86",
         "21-01-18",
         "14-01-19"
        ],
        [
         "2",
         "A631984D",
         "77799.33",
         "dollar",
         "46412.27",
         "26-01-18",
         "06-10-19"
        ],
        [
         "3",
         "93F2F951",
         "93875.24",
         "euro",
         "76563.35",
         "21-08-17",
         "10-07-19"
        ],
        [
         "4",
         "DE0A0882",
         "99998.35",
         "euro",
         "18669.01",
         "05-06-17",
         "15-01-19"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>acct_amount</th>\n",
       "      <th>acct_cur</th>\n",
       "      <th>inv_amount</th>\n",
       "      <th>account_opened</th>\n",
       "      <th>last_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8C35540A</td>\n",
       "      <td>44244.71</td>\n",
       "      <td>dollar</td>\n",
       "      <td>35500.50</td>\n",
       "      <td>03-05-18</td>\n",
       "      <td>30-09-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D5536652</td>\n",
       "      <td>86506.85</td>\n",
       "      <td>dollar</td>\n",
       "      <td>81921.86</td>\n",
       "      <td>21-01-18</td>\n",
       "      <td>14-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A631984D</td>\n",
       "      <td>77799.33</td>\n",
       "      <td>dollar</td>\n",
       "      <td>46412.27</td>\n",
       "      <td>26-01-18</td>\n",
       "      <td>06-10-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93F2F951</td>\n",
       "      <td>93875.24</td>\n",
       "      <td>euro</td>\n",
       "      <td>76563.35</td>\n",
       "      <td>21-08-17</td>\n",
       "      <td>10-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE0A0882</td>\n",
       "      <td>99998.35</td>\n",
       "      <td>euro</td>\n",
       "      <td>18669.01</td>\n",
       "      <td>05-06-17</td>\n",
       "      <td>15-01-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cust_id  acct_amount acct_cur  inv_amount account_opened last_transaction\n",
       "0  8C35540A     44244.71   dollar    35500.50       03-05-18         30-09-19\n",
       "1  D5536652     86506.85   dollar    81921.86       21-01-18         14-01-19\n",
       "2  A631984D     77799.33   dollar    46412.27       26-01-18         06-10-19\n",
       "3  93F2F951     93875.24     euro    76563.35       21-08-17         10-07-19\n",
       "4  DE0A0882     99998.35     euro    18669.01       05-06-17         15-01-19"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking = pd.read_csv(\"https://raw.githubusercontent.com/jhlopesalves/data-science-practice-notebook/refs/heads/main/Python/data_manipulation/pandas/cleaning_data/data/banking.csv\", usecols=lambda col: not col.startswith(\"Unnamed\"))\n",
    "banking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dcab27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows of acct_cur in banking that are equal to 'euro' and store them in the variable acct_eu.\n",
    "acct_eu = banking[\"acct_cur\"] == \"euro\"\n",
    "\n",
    "# Find all the rows of acct_amount in banking that fit the acct_eu condition, and convert them to USD by multiplying them with 1.1.\n",
    "banking.loc[acct_eu, \"acct_amount\"] = banking.loc[acct_eu, \"acct_amount\"] * 1.1\n",
    "\n",
    "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "banking.loc[acct_eu, \"acct_cur\"] = \"dollar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27f70162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "account_opened",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "21736049-7566-43e6-8fd5-eb4e524cbbd3",
       "rows": [
        [
         "0",
         "03-05-18"
        ],
        [
         "1",
         "21-01-18"
        ],
        [
         "2",
         "26-01-18"
        ],
        [
         "3",
         "21-08-17"
        ],
        [
         "4",
         "05-06-17"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "0    03-05-18\n",
       "1    21-01-18\n",
       "2    26-01-18\n",
       "3    21-08-17\n",
       "4    05-06-17\n",
       "Name: account_opened, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the header of account_opened\n",
    "banking[\"account_opened\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2e320ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert account_opened to datetime\n",
    "banking[\"account_opened\"] = pd.to_datetime(\n",
    "    banking[\"account_opened\"],\n",
    "    # Infer datetime format\n",
    "    infer_datetime_format=True,\n",
    "    # Return missing value for error\n",
    "    errors=\"coerce\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1980c0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "acct_year",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "57f156ef-09c8-48cf-80e4-774e0e83bc5a",
       "rows": [
        [
         "0",
         "2018"
        ],
        [
         "1",
         "2018"
        ],
        [
         "2",
         "2018"
        ],
        [
         "3",
         "2017"
        ],
        [
         "4",
         "2017"
        ],
        [
         "5",
         "2017"
        ],
        [
         "6",
         "2018"
        ],
        [
         "7",
         "2017"
        ],
        [
         "8",
         "2018"
        ],
        [
         "9",
         "2019"
        ],
        [
         "10",
         "2018"
        ],
        [
         "11",
         "2019"
        ],
        [
         "12",
         "2018"
        ],
        [
         "13",
         "2018"
        ],
        [
         "14",
         "2017"
        ],
        [
         "15",
         "2018"
        ],
        [
         "16",
         "2018"
        ],
        [
         "17",
         "2018"
        ],
        [
         "18",
         "2018"
        ],
        [
         "19",
         "2019"
        ],
        [
         "20",
         "2018"
        ],
        [
         "21",
         "2017"
        ],
        [
         "22",
         "2018"
        ],
        [
         "23",
         "2017"
        ],
        [
         "24",
         "2019"
        ],
        [
         "25",
         "2018"
        ],
        [
         "26",
         "2019"
        ],
        [
         "27",
         "2019"
        ],
        [
         "28",
         "2018"
        ],
        [
         "29",
         "2018"
        ],
        [
         "30",
         "2017"
        ],
        [
         "31",
         "2018"
        ],
        [
         "32",
         "2018"
        ],
        [
         "33",
         "2018"
        ],
        [
         "34",
         "2018"
        ],
        [
         "35",
         "2019"
        ],
        [
         "36",
         "2017"
        ],
        [
         "37",
         "2018"
        ],
        [
         "38",
         "2017"
        ],
        [
         "39",
         "2018"
        ],
        [
         "40",
         "2017"
        ],
        [
         "41",
         "2018"
        ],
        [
         "42",
         "2017"
        ],
        [
         "43",
         "2018"
        ],
        [
         "44",
         "2017"
        ],
        [
         "45",
         "2018"
        ],
        [
         "46",
         "2018"
        ],
        [
         "47",
         "2018"
        ],
        [
         "48",
         "2017"
        ],
        [
         "49",
         "2018"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 97
       }
      },
      "text/plain": [
       "0     2018\n",
       "1     2018\n",
       "2     2018\n",
       "3     2017\n",
       "4     2017\n",
       "      ... \n",
       "92    2017\n",
       "93    2018\n",
       "94    2018\n",
       "95    2017\n",
       "96    2017\n",
       "Name: acct_year, Length: 97, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the year from the amended account_opened column and assign it to the acct_year column.\n",
    "banking[\"acct_year\"] = banking[\"account_opened\"].dt.strftime(\"%Y\")\n",
    "\n",
    "# Print acct_year\n",
    "banking[\"acct_year\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb85b32",
   "metadata": {},
   "source": [
    "## Cross-Field Validation\n",
    "\n",
    "Data cleaning is often perceived as a column-by-column process: correcting data types, handling missing values, and standardising formats. However, a more profound level of data integrity comes from **cross-field validation**. This is the practice of using multiple fields within a dataset to verify and enforce the logical rules and constraints that should exist between them. It is a critical step that elevates data cleaning from mere correction to logical verification.\n",
    "\n",
    "While single-field validation ensures that a column's values are plausible in isolation (e.g., an 'Age' column contains reasonable numbers), cross-field validation ensures that these values make sense in concert with others (e.g., the 'Age' column is consistent with the 'Date of Birth' column). These checks are almost always derived from real-world business logic or physical constraints, and failing to perform them can lead to fundamentally flawed analyses.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame for validating an aggregate sum\n",
    "df_inventory = pd.DataFrame({\n",
    "    'product_id': ['A1', 'A2', 'B1', 'B2', 'C1'],\n",
    "    'warehouse_stock': [100, 150, 200, 120, 180],\n",
    "    'in_transit': [20, 30, 40, 25, 35],\n",
    "    'reported_total_stock': [120, 180, 250, 145, 215] # Contains one error\n",
    "})\n",
    "\n",
    "# Sample DataFrame for validating derived information\n",
    "# Using a fixed date for today to ensure the example is reproducible\n",
    "today = pd.to_datetime('2025-07-07')\n",
    "df_users = pd.DataFrame({\n",
    "    'user_id': [101, 102, 103, 104],\n",
    "    'date_of_birth': pd.to_datetime(['1990-05-15', '1985-11-20', '2000-02-10', '1995-09-30']),\n",
    "    'reported_age': [35, 39, 23, 29] # Contains one error\n",
    "})\n",
    "```\n",
    "\n",
    "\n",
    "### Validating Against an Aggregate Sum\n",
    "\n",
    "A frequent scenario for cross-field validation involves records where one column purports to be the sum of several others. This is common in financial data, sales records, and inventory management. The validation checks whether the reported total is arithmetically correct.\n",
    "\n",
    "  * **Why & When to Use It**: This technique is essential whenever a dataset contains both constituent parts and a pre-calculated total. It serves as a powerful audit to detect data entry errors, calculation bugs in the source system, or data corruption. You cannot trust the `reported_total_stock` column, for instance, without first verifying it against its components.\n",
    "\n",
    "  * **A Pythonic Approach**: The most efficient way to perform this check in `pandas` is through vectorized operations, which are significantly faster and more readable than row-by-row loops.\n",
    "\n",
    "1.  **Select & Sum**: Isolate the component columns and sum them horizontally across each row (`axis=1`).\n",
    "2.  **Compare**: Compare the newly calculated sum (a `pandas` Series) with the reported total column. This comparison yields a boolean Series (`True` for consistent rows, `False` for inconsistent ones).\n",
    "3.  **Filter**: Use this boolean Series to partition the original DataFrame into two: one containing the consistent records and another containing the discrepancies.\n",
    "\n",
    "\n",
    "```python\n",
    "# 1. Calculate the true sum from the component columns\n",
    "calculated_sum = df_inventory[['warehouse_stock', 'in_transit']].sum(axis=1)\n",
    "\n",
    "# 2. Compare the calculated sum to the reported total\n",
    "is_consistent = (calculated_sum == df_inventory['reported_total_stock'])\n",
    "\n",
    "# 3. Filter the DataFrame to isolate consistent and inconsistent records\n",
    "consistent_inventory = df_inventory[is_consistent]\n",
    "inconsistent_inventory = df_inventory[~is_consistent] # The ~ operator inverts the boolean mask\n",
    "\n",
    "print(\"--- Calculated vs. Reported Totals ---\")\n",
    "print(df_inventory.assign(calculated_sum=calculated_sum))\n",
    "\n",
    "print(\"\\n--- Inconsistent Records Found ---\")\n",
    "print(inconsistent_inventory)\n",
    "```\n",
    "\n",
    "This process, Jhonatan, not only identifies the problematic record (`B1`) but does so in a scalable and computationally efficient manner.\n",
    "\n",
    "### Validating Derived Information\n",
    "\n",
    "Another critical form of cross-field validation involves checking fields that can be logically or mathematically derived from one another. A classic example is verifying a person's reported age against their date of birth.\n",
    "\n",
    "  * **Why & When to Use It**: This is necessary when data redundancy exists and could lead to contradictions. If a user updates their date of birth but not their age, the record becomes logically inconsistent. Validating derived fields ensures that all related information is synchronised and accurate.\n",
    "\n",
    "  * **A Pythonic Approach**: The process is similar to the aggregate check but involves a date-based calculation.\n",
    "\n",
    "\n",
    "1.  **Ensure Correct Types**: Confirm the date column is in the proper `datetime` format using `pd.to_datetime()`.\n",
    "2.  **Calculate the Derived Value**: Compute the age from the date of birth. A common and robust method is to find the time difference in days and divide by the average number of days in a year. A simpler, though slightly less precise, method is to subtract the years.\n",
    "3.  **Compare & Filter**: As before, compare the calculated age with the reported age to create a boolean mask and partition the data.\n",
    "\n",
    "\n",
    "```python\n",
    "# 1. Ensure date_of_birth is a datetime object (already done in setup)\n",
    "\n",
    "# 2. Calculate the age based on the date of birth and today's date\n",
    "# This calculation gives the age in years, accounting for completed years.\n",
    "calculated_age = (today.year - df_users['date_of_birth'].dt.year) - \\\n",
    "                 ((today.month < df_users['date_of_birth'].dt.month) | \\\n",
    "                  ((today.month == df_users['date_of_birth'].dt.month) & \\\n",
    "                   (today.day < df_users['date_of_birth'].dt.day))).astype(int)\n",
    "\n",
    "\n",
    "# 3. Compare the calculated age to the reported age\n",
    "is_age_consistent = (calculated_age == df_users['reported_age'])\n",
    "\n",
    "# 4. Filter to find inconsistencies\n",
    "inconsistent_users = df_users[~is_age_consistent]\n",
    "\n",
    "print(\"--- Calculated vs. Reported Ages ---\")\n",
    "print(df_users.assign(calculated_age=calculated_age))\n",
    "\n",
    "print(\"\\n--- Inconsistent User Records ---\")\n",
    "print(inconsistent_users)\n",
    "```\n",
    "\n",
    "This validation correctly flags user `103`, whose reported age of 23 is inconsistent with a birth date in the year 2000 (which would make them 25).\n",
    "\n",
    "### What to Do with Inconsistent Records?\n",
    "\n",
    "Identifying an inconsistency is only half the battle. Deciding how to resolve it is a critical step that depends heavily on the project's context, the data's source, and the analytical goals. There is no universal solution, only a spectrum of strategies.\n",
    "\n",
    "#### Strategy 1: Apply Rules from Domain Knowledge (The Ideal)\n",
    "\n",
    "This is the most powerful strategy. It involves using your understanding of the data's context to make an informed correction.\n",
    "\n",
    "  * **When to Use**: This is appropriate when you can confidently designate one field as the \"source of truth.\" In our inventory example, if we trust the on-the-ground counts (`warehouse_stock`, `in_transit`), we can simply recalculate and overwrite the `reported_total_stock`. In the user age example, the `date_of_birth` is almost certainly more reliable than a self-reported `age`.\n",
    "  * **Action**: Overwrite the incorrect, derived, or aggregated field with the newly calculated, correct value. This preserves the entire record while ensuring its integrity.\n",
    "\n",
    "#### Strategy 2: Set to Missing and Impute (The Pragmatic Compromise)\n",
    "\n",
    "Sometimes, you cannot determine which field is correct, or the incorrect field is essential for a downstream model.\n",
    "\n",
    "  * **When to Use**: Use this when you cannot apply domain knowledge to make a correction, but you cannot afford to lose the entire record. For example, if both the component and total stock numbers are suspect, you might set the `reported_total_stock` to `NaN`.\n",
    "  * **Action**: Replace the inconsistent value(s) with `np.nan`. This explicitly flags the data as missing. Later, you can use an imputation strategy (e.g., filling with the mean, median, or using a predictive model) to estimate the value, if required for your analysis.\n",
    "\n",
    "#### Strategy 3: Drop the Data (The Last Resort)\n",
    "\n",
    "Removing records entirely is the simplest but most drastic option.\n",
    "\n",
    "  * **When to Use**: This is justifiable only when the inconsistent records constitute a very small percentage of your dataset, and their removal is unlikely to introduce bias. It is also an option when the inconsistent fields are so critical that the entire record is untrustworthy and cannot be repaired.\n",
    "  * **Action**: Use boolean indexing to filter the DataFrame, keeping only the consistent records. Be aware that this reduces your sample size and can, if not done carefully, skew your dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2f8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
